{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE7fXh-OSJYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdf93f89-cec6-40c1-8fa2-389852b54b1a"
      },
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip -qq install torchtext==0.3.1\n",
        "!pip -qq install torchvision==0.2.1\n",
        "!pip -qq install spacy==2.0.16\n",
        "!python -m spacy download en\n",
        "!pip install sacremoses==0.0.5\n",
        "!pip install subword_nmt==0.3.5\n",
        "!wget -qq http://www.manythings.org/anki/rus-eng.zip \n",
        "!unzip rus-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.5MB 33kB/s \n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 23.3MB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 614kB 33.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 57.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 65.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 14.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 65.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 53.4MB/s \n",
            "\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement spacy>=2.0.18, but you'll have spacy 2.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.0.16 which is incompatible.\u001b[0m\n",
            "Collecting en_core_web_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K     |████████████████████████████████| 37.4MB 1.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.0.0-cp36-none-any.whl size=37405977 sha256=5480def6b9aa2b7e06df06f93eb95afb1011fc42885742cf1cf3be40b07c32db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g9pnuut_/wheels/54/7c/d8/f86364af8fbba7258e14adae115f18dd2c91552406edc3fdaa\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Collecting sacremoses==0.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/c4/9d4cdd0e3e02d3328bb4e6764da25b147ce72d87d3d627e4f90611755411/sacremoses-0.0.5.tar.gz (102kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.5) (1.12.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.5-cp36-none-any.whl size=133531 sha256=1bd551f64f77448a98e917273de9b6259c901233db75b098a3730eec59f9746d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/b4/f5/8ca724b21fc983eee2c9b99a7db69f85480c330a5bf6d8d546\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.5\n",
            "Collecting subword_nmt==0.3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/14/f870780204476815af1aa11a20bfde91fbe588712a1e900b32c079beb7ea/subword_nmt-0.3.5-py2.py3-none-any.whl\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.5\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhvfH55PUJ8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txWqIO_74A4s",
        "colab_type": "text"
      },
      "source": [
        "# Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRiSIqhQcP2W",
        "colab_type": "text"
      },
      "source": [
        "Мы уже несколько раз смотрели на эту картинку:\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "В POS tagging мы (ну, некоторые точно) использовали важную идею: сначала некоторой функцией над символами строился эмбеддинг для слова (например, many to one rnn'кой на картинке). Потом другая rnn'ка строила эмбеддинги слов с учетом их контекста. А дальше это всё классифицируется логистической регрессией.\n",
        "\n",
        "Тут важно то, что мы обучаем encoder для построения эмбеддингов end2end - прямо в составе сети (это основное отличие нейросетей от классических подходов - в умении делать end2end).\n",
        "\n",
        "Другое, что мы делали - это языковые модели. Вот, типа такого:\n",
        "![](https://hsto.org/web/dc1/7c2/c4e/dc17c2c4e9ac434eb5346ada2c412c9a.png)\n",
        "\n",
        "Обратите внимание на красную стрелку - она показывает передачу скрытого состояния, которое отвечает за память сети.\n",
        "\n",
        "А теперь совместим эти две идеи:\n",
        "\n",
        "![](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg)  \n",
        "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
        "\n",
        "Выглядит все почти как языковая модель, но в синей части предсказания не делаются, используется только последнее скрытое состояние.\n",
        "\n",
        "Синяя часть сети называется энкодер, она строит эмбеддинг последовательности. Красная часть - декодер, работает как обычная языковая модель, но учитывает результат работы энкодера.\n",
        "\n",
        "В итоге, энкодер учится эффективно извлекать смысл из последовательности слов, а декодер должен строить по ним новую последовательность. Это может быть последовательностью слов перевода, или последовательностью слов в ответе чат бота, или еще чем-то в зависимости от вашей испорченности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNkst1XkYN6",
        "colab_type": "text"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRLNIzJkkqkM",
        "colab_type": "text"
      },
      "source": [
        "Начнем с чтения данных. Возьмем их у anki, поэтому они немного специфичны:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2vjzBVqZF0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b9cf999a-b6d7-44db-c746-8fdd46985791"
      },
      "source": [
        "!shuf -n 10 rus.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom told me I was wrong.\tТом сказал мне, что я неправ.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3200010 (CK) & #3701605 (odexed)\n",
            "I agree with this statement.\tЯ согласен с этим утверждением.\tCC-BY 2.0 (France) Attribution: tatoeba.org #4529829 (CK) & #3091951 (marafon)\n",
            "Just sit there.\tПросто сядь там.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2249456 (CK) & #4203702 (odexed)\n",
            "The match ended in a draw.\tМатч закончился вничью.\tCC-BY 2.0 (France) Attribution: tatoeba.org #267390 (CK) & #2462560 (Lenin_1917)\n",
            "I have nothing to do with the affair.\tЯ не имею никакого отношения к делу.\tCC-BY 2.0 (France) Attribution: tatoeba.org #29001 (CK) & #2580413 (odexed)\n",
            "We can't do this without Tom's help.\tМы не можем этого сделать без помощи Тома.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5958362 (CK) & #8158281 (odexed)\n",
            "Why didn't you take the day off?\tПочему ты не взял выходной?\tCC-BY 2.0 (France) Attribution: tatoeba.org #3496781 (CK) & #4971107 (sharptoothed)\n",
            "Do you have it?\tОна у Вас?\tCC-BY 2.0 (France) Attribution: tatoeba.org #2192241 (acbarbosa) & #5779351 (marafon)\n",
            "Who did Tom sing for?\tДля кого Том пел?\tCC-BY 2.0 (France) Attribution: tatoeba.org #6351170 (CK) & #6614538 (marafon)\n",
            "Tom moved the chair closer to the window.\tТом пододвинул стул к окну.\tCC-BY 2.0 (France) Attribution: tatoeba.org #6665620 (CK) & #8299586 (marafon)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOVlO5_Qlg5y",
        "colab_type": "text"
      },
      "source": [
        "Токенизируем их:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsOvtO0fpCHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN)\n",
        "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "fields = [('source', source_field), ('target', target_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qA15-tcudjw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1ccba23f-4703-44d1-80ee-4c8347e366af"
      },
      "source": [
        "source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " \"'s\",\n",
              " 'surprising',\n",
              " 'that',\n",
              " 'you',\n",
              " 'have',\n",
              " \"n't\",\n",
              " 'heard',\n",
              " 'anything',\n",
              " 'about',\n",
              " 'her',\n",
              " 'wedding',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HguPFHc5sjcD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c180f2b7-c5a9-4445-f6e2-af54cb751490"
      },
      "source": [
        "target_field.preprocess('Удивительно, что ты ничего не слышал о её свадьбе.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Удивительно',\n",
              " ',',\n",
              " 'что',\n",
              " 'ты',\n",
              " 'ничего',\n",
              " 'не',\n",
              " 'слышал',\n",
              " 'о',\n",
              " 'её',\n",
              " 'свадьбе',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO-gix7yoBjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c291bccb-c926-4512-e8ed-9a138e8cb7cb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "MAX_TOKENS_COUNT = 16\n",
        "SUBSET_SIZE = .3\n",
        "\n",
        "examples = []\n",
        "with open('rus.txt') as f:\n",
        "    for line in tqdm(f, total=328190):\n",
        "        #print(' ')\n",
        "        #print(line.split('\\t'))\n",
        "        source_text, target_text, _ = line.split('\\t')\n",
        "        source_text = source_field.preprocess(source_text)\n",
        "        target_text = target_field.preprocess(target_text)\n",
        "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "            if np.random.rand() < SUBSET_SIZE:\n",
        "                examples.append(Example.fromlist([source_text, target_text], fields))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "380911it [00:35, 10706.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8uCsMEglm6V",
        "colab_type": "text"
      },
      "source": [
        "Построим датасеты:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOBgLAgVTrk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c8e7a491-7d90-4300-839f-c1c7b84634a8"
      },
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 256), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 96580\n",
            "Test size = 17043\n",
            "Source vocab size = 5522\n",
            "Target vocab size = 11231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5sMz-hfBvCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d38628e1-fa91-4fc4-9434-7c2501394413"
      },
      "source": [
        "source_field.process([source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  45],\n",
              "        [  15],\n",
              "        [5425],\n",
              "        [  12],\n",
              "        [   6],\n",
              "        [  22],\n",
              "        [   9],\n",
              "        [ 269],\n",
              "        [ 127],\n",
              "        [  54],\n",
              "        [  99],\n",
              "        [1001],\n",
              "        [   3],\n",
              "        [   2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1yFzRg2xAjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd3d4f0d-f351-4474-8ff7-2bbde8400139"
      },
      "source": [
        "source_field.vocab.itos"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '</s>',\n",
              " '.',\n",
              " 'I',\n",
              " 'Tom',\n",
              " 'you',\n",
              " 'to',\n",
              " '?',\n",
              " \"n't\",\n",
              " 'the',\n",
              " 'a',\n",
              " 'that',\n",
              " 'do',\n",
              " 'is',\n",
              " \"'s\",\n",
              " 'me',\n",
              " 'was',\n",
              " 'in',\n",
              " 'did',\n",
              " 'You',\n",
              " 'it',\n",
              " 'have',\n",
              " 'know',\n",
              " 'of',\n",
              " 'Mary',\n",
              " 'for',\n",
              " ',',\n",
              " \"'m\",\n",
              " 'Do',\n",
              " 'this',\n",
              " 'We',\n",
              " 'want',\n",
              " 'your',\n",
              " 'be',\n",
              " 'think',\n",
              " 'with',\n",
              " 'he',\n",
              " 'not',\n",
              " 'my',\n",
              " 'are',\n",
              " \"'re\",\n",
              " 'He',\n",
              " 'what',\n",
              " 'The',\n",
              " 'It',\n",
              " 'on',\n",
              " 'like',\n",
              " \"'ll\",\n",
              " 'go',\n",
              " 'and',\n",
              " 'his',\n",
              " \"'ve\",\n",
              " 'What',\n",
              " 'about',\n",
              " 'at',\n",
              " 'here',\n",
              " 'has',\n",
              " 'told',\n",
              " 'can',\n",
              " 'going',\n",
              " 'will',\n",
              " 'How',\n",
              " 'were',\n",
              " 'very',\n",
              " 'time',\n",
              " 'does',\n",
              " 'help',\n",
              " 'had',\n",
              " 'She',\n",
              " 'one',\n",
              " 'need',\n",
              " 'Why',\n",
              " 'we',\n",
              " 'Boston',\n",
              " 'would',\n",
              " 'all',\n",
              " 'tell',\n",
              " 'ca',\n",
              " 'us',\n",
              " 'Did',\n",
              " 'said',\n",
              " 'him',\n",
              " \"'d\",\n",
              " 'as',\n",
              " 'This',\n",
              " 'Are',\n",
              " 'get',\n",
              " 'That',\n",
              " 'there',\n",
              " 'should',\n",
              " 'They',\n",
              " 'never',\n",
              " 'up',\n",
              " 'been',\n",
              " 'out',\n",
              " 'could',\n",
              " 'see',\n",
              " 'got',\n",
              " 'her',\n",
              " 'so',\n",
              " 'from',\n",
              " 'by',\n",
              " 'come',\n",
              " 'an',\n",
              " 'good',\n",
              " 'much',\n",
              " 'thought',\n",
              " 'Let',\n",
              " 'just',\n",
              " 'French',\n",
              " 'My',\n",
              " 'back',\n",
              " 'now',\n",
              " 'than',\n",
              " 'Is',\n",
              " 'who',\n",
              " 'no',\n",
              " 'wo',\n",
              " 'too',\n",
              " 'how',\n",
              " 'home',\n",
              " 'talk',\n",
              " 'wanted',\n",
              " 'car',\n",
              " 'still',\n",
              " 'There',\n",
              " 'anything',\n",
              " 'something',\n",
              " 'Can',\n",
              " 'really',\n",
              " 'knew',\n",
              " 'more',\n",
              " 'if',\n",
              " 'Who',\n",
              " 'take',\n",
              " 'Please',\n",
              " 'already',\n",
              " 'Where',\n",
              " 'three',\n",
              " 'money',\n",
              " 'sure',\n",
              " 'say',\n",
              " 'leave',\n",
              " 'work',\n",
              " 'last',\n",
              " 'today',\n",
              " 'asked',\n",
              " 'where',\n",
              " 'find',\n",
              " 'right',\n",
              " 'again',\n",
              " 'lot',\n",
              " 'doing',\n",
              " 'always',\n",
              " 'any',\n",
              " 'when',\n",
              " 'happened',\n",
              " 'only',\n",
              " 'why',\n",
              " 'some',\n",
              " 'day',\n",
              " 'buy',\n",
              " 'left',\n",
              " 'many',\n",
              " 'made',\n",
              " 'long',\n",
              " 'Have',\n",
              " 'eat',\n",
              " 'better',\n",
              " 'tomorrow',\n",
              " 'but',\n",
              " 'speak',\n",
              " 'house',\n",
              " 'am',\n",
              " 'went',\n",
              " 'knows',\n",
              " 'Tell',\n",
              " 'stay',\n",
              " 'done',\n",
              " 'love',\n",
              " 'ask',\n",
              " 'hope',\n",
              " 'saw',\n",
              " 'off',\n",
              " 'make',\n",
              " 'people',\n",
              " 'them',\n",
              " 'When',\n",
              " 'room',\n",
              " 'they',\n",
              " 'book',\n",
              " 'before',\n",
              " 'must',\n",
              " 'yesterday',\n",
              " 'believe',\n",
              " 'everything',\n",
              " 'school',\n",
              " 'Australia',\n",
              " 'well',\n",
              " 'old',\n",
              " 'wants',\n",
              " 'way',\n",
              " 'give',\n",
              " 'wrong',\n",
              " 'look',\n",
              " 'understand',\n",
              " 'or',\n",
              " 'If',\n",
              " 'our',\n",
              " 'yet',\n",
              " '!',\n",
              " 'call',\n",
              " 'ever',\n",
              " 'alone',\n",
              " 'new',\n",
              " 'wait',\n",
              " '\"',\n",
              " 'father',\n",
              " 'years',\n",
              " 'down',\n",
              " 'she',\n",
              " 'live',\n",
              " 'job',\n",
              " 'came',\n",
              " 'married',\n",
              " 'into',\n",
              " 'happy',\n",
              " 'win',\n",
              " 'let',\n",
              " 'happen',\n",
              " 'dog',\n",
              " 'little',\n",
              " 'read',\n",
              " 'friends',\n",
              " 'next',\n",
              " '-',\n",
              " 'other',\n",
              " 'bought',\n",
              " 'else',\n",
              " 'late',\n",
              " 'afraid',\n",
              " 'nothing',\n",
              " 'used',\n",
              " 'busy',\n",
              " 'name',\n",
              " 'away',\n",
              " 'often',\n",
              " 'every',\n",
              " 'play',\n",
              " 'problem',\n",
              " 'put',\n",
              " 'anyone',\n",
              " 'door',\n",
              " 'night',\n",
              " 'idea',\n",
              " 'gave',\n",
              " 'two',\n",
              " 'took',\n",
              " 'found',\n",
              " 'looking',\n",
              " 'able',\n",
              " 'first',\n",
              " 'seen',\n",
              " 'week',\n",
              " 'says',\n",
              " 'over',\n",
              " 'remember',\n",
              " 'children',\n",
              " 'heard',\n",
              " 'No',\n",
              " 'anymore',\n",
              " 'tried',\n",
              " 'enough',\n",
              " 'both',\n",
              " 'hard',\n",
              " 'A',\n",
              " 'morning',\n",
              " 'even',\n",
              " 'lost',\n",
              " 'glad',\n",
              " 'man',\n",
              " 'mother',\n",
              " 'soon',\n",
              " 'after',\n",
              " 'Your',\n",
              " 'without',\n",
              " 'likes',\n",
              " 'try',\n",
              " 'answer',\n",
              " 'talking',\n",
              " 'tired',\n",
              " 'truth',\n",
              " 'waiting',\n",
              " 'year',\n",
              " 'almost',\n",
              " 'himself',\n",
              " 'stop',\n",
              " 'yourself',\n",
              " 'Does',\n",
              " 'hear',\n",
              " 'same',\n",
              " 'wish',\n",
              " 'may',\n",
              " 'friend',\n",
              " 'ready',\n",
              " 'thing',\n",
              " 'bus',\n",
              " 'feel',\n",
              " 'plan',\n",
              " 'question',\n",
              " 'life',\n",
              " 'water',\n",
              " 'looks',\n",
              " 'bad',\n",
              " 'died',\n",
              " 'started',\n",
              " 'together',\n",
              " 'cold',\n",
              " 'needs',\n",
              " 'open',\n",
              " 'drink',\n",
              " 'please',\n",
              " 'hungry',\n",
              " 'brother',\n",
              " 'myself',\n",
              " 'early',\n",
              " 'looked',\n",
              " 'anybody',\n",
              " 'decided',\n",
              " 'true',\n",
              " 'young',\n",
              " 'beautiful',\n",
              " 'things',\n",
              " 'coffee',\n",
              " 'bed',\n",
              " 'Give',\n",
              " 'forget',\n",
              " 'parents',\n",
              " 'Nobody',\n",
              " 'sorry',\n",
              " 'coming',\n",
              " 'letter',\n",
              " 'questions',\n",
              " 'their',\n",
              " 'these',\n",
              " 'best',\n",
              " 'care',\n",
              " 'kind',\n",
              " 'ago',\n",
              " 'each',\n",
              " 'called',\n",
              " 'days',\n",
              " 'keep',\n",
              " 'mind',\n",
              " 'use',\n",
              " 'person',\n",
              " 'place',\n",
              " 'watch',\n",
              " 'trying',\n",
              " 'Would',\n",
              " 'Could',\n",
              " 'change',\n",
              " 'phone',\n",
              " 'train',\n",
              " 'around',\n",
              " 'swim',\n",
              " 'working',\n",
              " 'surprised',\n",
              " 'big',\n",
              " 'books',\n",
              " 'sleep',\n",
              " 'met',\n",
              " 'English',\n",
              " 'few',\n",
              " 'police',\n",
              " 'while',\n",
              " 'easy',\n",
              " 'meet',\n",
              " 'Everyone',\n",
              " 'drive',\n",
              " 'getting',\n",
              " 'sick',\n",
              " 'trust',\n",
              " 'doctor',\n",
              " 'wife',\n",
              " 'angry',\n",
              " 'another',\n",
              " 'wonder',\n",
              " 'family',\n",
              " 'until',\n",
              " 'Which',\n",
              " 'agree',\n",
              " 'gone',\n",
              " 'needed',\n",
              " 'Monday',\n",
              " 'Will',\n",
              " 'TV',\n",
              " 'sister',\n",
              " 'learn',\n",
              " 'show',\n",
              " 'being',\n",
              " 'killed',\n",
              " 'such',\n",
              " 'teacher',\n",
              " 'walk',\n",
              " 'His',\n",
              " 'difficult',\n",
              " 'everyone',\n",
              " 'Just',\n",
              " 'pay',\n",
              " 'All',\n",
              " 'hours',\n",
              " 'mine',\n",
              " 'exactly',\n",
              " 'forgot',\n",
              " 'sing',\n",
              " 'OK',\n",
              " 'hate',\n",
              " 'dinner',\n",
              " 'rain',\n",
              " 'food',\n",
              " 'later',\n",
              " 'miss',\n",
              " 'mistake',\n",
              " 'John',\n",
              " 'cat',\n",
              " 'usually',\n",
              " 'son',\n",
              " 'times',\n",
              " 'turn',\n",
              " 'wearing',\n",
              " 'Take',\n",
              " 'hurt',\n",
              " 'might',\n",
              " 'longer',\n",
              " 'helped',\n",
              " 'thirty',\n",
              " 'lunch',\n",
              " 'lived',\n",
              " 'lives',\n",
              " 'stupid',\n",
              " 'May',\n",
              " 'someone',\n",
              " 'write',\n",
              " 'living',\n",
              " 'seem',\n",
              " 'seems',\n",
              " 'Everybody',\n",
              " 'meeting',\n",
              " 'probably',\n",
              " 'quite',\n",
              " 'start',\n",
              " '2:30',\n",
              " 'picture',\n",
              " 'tonight',\n",
              " 'favorite',\n",
              " 'table',\n",
              " 'because',\n",
              " 'finished',\n",
              " 'shoes',\n",
              " 'careful',\n",
              " 'eyes',\n",
              " 'study',\n",
              " 'explain',\n",
              " 'hands',\n",
              " 'homework',\n",
              " 'matter',\n",
              " 'yours',\n",
              " 'broke',\n",
              " 'girl',\n",
              " 'liked',\n",
              " 'movie',\n",
              " 'important',\n",
              " 'Maybe',\n",
              " 'boy',\n",
              " 'minutes',\n",
              " 'music',\n",
              " 'great',\n",
              " 'party',\n",
              " 'pretty',\n",
              " 'window',\n",
              " 'most',\n",
              " 'turned',\n",
              " 'world',\n",
              " 'box',\n",
              " 'chance',\n",
              " 'Go',\n",
              " 'own',\n",
              " 'hair',\n",
              " 'thinks',\n",
              " 'mean',\n",
              " 'rich',\n",
              " 'Look',\n",
              " 'apologize',\n",
              " 'kill',\n",
              " 'makes',\n",
              " 'story',\n",
              " 'older',\n",
              " 'once',\n",
              " 'age',\n",
              " 'far',\n",
              " 'interesting',\n",
              " 'Japan',\n",
              " 'fire',\n",
              " 'Get',\n",
              " 'bit',\n",
              " 'class',\n",
              " 'free',\n",
              " 'hand',\n",
              " 'Stop',\n",
              " 'caught',\n",
              " 'dead',\n",
              " 'number',\n",
              " 'playing',\n",
              " 'lie',\n",
              " 'works',\n",
              " 'ten',\n",
              " 'breakfast',\n",
              " 'paid',\n",
              " 'watching',\n",
              " 'Put',\n",
              " 'accident',\n",
              " 'asleep',\n",
              " 'ate',\n",
              " 'drunk',\n",
              " 'having',\n",
              " 'leaving',\n",
              " 'reading',\n",
              " 'summer',\n",
              " 'visit',\n",
              " 'worried',\n",
              " 'Come',\n",
              " 'fell',\n",
              " 'office',\n",
              " 'red',\n",
              " 'arrived',\n",
              " 'close',\n",
              " 'finish',\n",
              " 'tea',\n",
              " 'tree',\n",
              " 'word',\n",
              " 'Were',\n",
              " 'country',\n",
              " 'eating',\n",
              " 'key',\n",
              " 'nice',\n",
              " 'born',\n",
              " 'secret',\n",
              " 'since',\n",
              " 'talked',\n",
              " 'run',\n",
              " 'whether',\n",
              " 'worry',\n",
              " 'Canadian',\n",
              " 'become',\n",
              " 'child',\n",
              " 'clothes',\n",
              " 'dark',\n",
              " 'planning',\n",
              " 'plans',\n",
              " 'proud',\n",
              " 'small',\n",
              " 'October',\n",
              " 'cost',\n",
              " 'park',\n",
              " 'lose',\n",
              " 'promised',\n",
              " 'under',\n",
              " 'Was',\n",
              " 'die',\n",
              " 'hospital',\n",
              " 'hot',\n",
              " 'kept',\n",
              " 'promise',\n",
              " 'telling',\n",
              " 'those',\n",
              " 'decision',\n",
              " 'fast',\n",
              " 'fun',\n",
              " 'hour',\n",
              " 'kids',\n",
              " 'wear',\n",
              " 'cry',\n",
              " 'everybody',\n",
              " 'hat',\n",
              " 'Thanks',\n",
              " 'advice',\n",
              " 'game',\n",
              " 'loved',\n",
              " 'outside',\n",
              " 'tennis',\n",
              " 'changed',\n",
              " 'keys',\n",
              " 'light',\n",
              " 'won',\n",
              " 'wrote',\n",
              " 'expect',\n",
              " 'sit',\n",
              " 'These',\n",
              " 'daughter',\n",
              " 'five',\n",
              " 'safe',\n",
              " 'supposed',\n",
              " 'felt',\n",
              " 'interested',\n",
              " 'shirt',\n",
              " 'umbrella',\n",
              " 'baby',\n",
              " 'station',\n",
              " 'town',\n",
              " 'began',\n",
              " 'month',\n",
              " 'scared',\n",
              " 'trouble',\n",
              " 'wine',\n",
              " 'brought',\n",
              " 'saying',\n",
              " 'Thank',\n",
              " 'fix',\n",
              " 'move',\n",
              " 'ran',\n",
              " 'speaks',\n",
              " 'stayed',\n",
              " 'strange',\n",
              " 'Her',\n",
              " 'Try',\n",
              " 'broken',\n",
              " 'possible',\n",
              " 'problems',\n",
              " 'six',\n",
              " 'Our',\n",
              " 'In',\n",
              " 'birthday',\n",
              " 'comes',\n",
              " 'city',\n",
              " 'quickly',\n",
              " 'then',\n",
              " 'expensive',\n",
              " 'face',\n",
              " 'listen',\n",
              " 'milk',\n",
              " 'students',\n",
              " 'woman',\n",
              " 'younger',\n",
              " 'beer',\n",
              " 'choice',\n",
              " 'fault',\n",
              " 'news',\n",
              " 'song',\n",
              " 'spent',\n",
              " 'thinking',\n",
              " 'touch',\n",
              " 'worked',\n",
              " 'behind',\n",
              " 'fish',\n",
              " 'high',\n",
              " 'stopped',\n",
              " 'taking',\n",
              " 'clean',\n",
              " 'cut',\n",
              " 'dollars',\n",
              " 'flowers',\n",
              " 'hotel',\n",
              " 'weather',\n",
              " 'death',\n",
              " 'different',\n",
              " 'evening',\n",
              " 'floor',\n",
              " 'team',\n",
              " 'upset',\n",
              " 'end',\n",
              " 'invited',\n",
              " 'loves',\n",
              " 'serious',\n",
              " 'snow',\n",
              " 'Some',\n",
              " 'against',\n",
              " 'cook',\n",
              " 'crazy',\n",
              " 'driver',\n",
              " 'One',\n",
              " 'break',\n",
              " 'goes',\n",
              " 'lying',\n",
              " 'sleeping',\n",
              " 'computer',\n",
              " 'crying',\n",
              " 'mistakes',\n",
              " 'thank',\n",
              " 'anywhere',\n",
              " 'cup',\n",
              " 'dance',\n",
              " 'gets',\n",
              " 'rest',\n",
              " 'became',\n",
              " 'business',\n",
              " 'catch',\n",
              " 'kiss',\n",
              " 'missed',\n",
              " 'moved',\n",
              " 'either',\n",
              " 'hurry',\n",
              " 'likely',\n",
              " 'sad',\n",
              " 'sat',\n",
              " 'through',\n",
              " 'girlfriend',\n",
              " 'large',\n",
              " 'spend',\n",
              " 'store',\n",
              " 'studying',\n",
              " 'bicycle',\n",
              " 'feeling',\n",
              " 'fishing',\n",
              " 'meat',\n",
              " 'refused',\n",
              " 'white',\n",
              " 'Here',\n",
              " 'Japanese',\n",
              " 'closed',\n",
              " 'eaten',\n",
              " 'guitar',\n",
              " 'opened',\n",
              " 'sitting',\n",
              " 'Ask',\n",
              " 'Now',\n",
              " 'black',\n",
              " 'full',\n",
              " 'lucky',\n",
              " 'reason',\n",
              " 'stand',\n",
              " 'waited',\n",
              " 'weekend',\n",
              " 'whole',\n",
              " 'writing',\n",
              " 'completely',\n",
              " 'glass',\n",
              " 'part',\n",
              " 'teach',\n",
              " 'Both',\n",
              " 'Christmas',\n",
              " 'alive',\n",
              " 'wash',\n",
              " 'desk',\n",
              " 'empty',\n",
              " 'known',\n",
              " 'language',\n",
              " 'sent',\n",
              " 'spoke',\n",
              " 'street',\n",
              " 'test',\n",
              " 'heart',\n",
              " 'list',\n",
              " 'message',\n",
              " 'near',\n",
              " 'paper',\n",
              " 'rather',\n",
              " 'strong',\n",
              " 'swimming',\n",
              " 'tall',\n",
              " 'Be',\n",
              " 'Has',\n",
              " 'afternoon',\n",
              " 'hit',\n",
              " 'point',\n",
              " 'present',\n",
              " 'prison',\n",
              " 'sell',\n",
              " 'famous',\n",
              " 'half',\n",
              " 'kitchen',\n",
              " 'return',\n",
              " 'along',\n",
              " 'blame',\n",
              " 'borrow',\n",
              " 'dangerous',\n",
              " 'enjoy',\n",
              " 'finally',\n",
              " 'happens',\n",
              " 'husband',\n",
              " 'ice',\n",
              " 'inside',\n",
              " 'making',\n",
              " 'rules',\n",
              " 'Keep',\n",
              " 'Someone',\n",
              " 'attention',\n",
              " 'lied',\n",
              " 'order',\n",
              " 'road',\n",
              " 'taxi',\n",
              " 'arrested',\n",
              " 'between',\n",
              " 'fired',\n",
              " 'head',\n",
              " 'horse',\n",
              " 'restaurant',\n",
              " 'short',\n",
              " 'trip',\n",
              " 'twice',\n",
              " 'cake',\n",
              " 'dress',\n",
              " 'drinking',\n",
              " 'glasses',\n",
              " 'happening',\n",
              " 'Everything',\n",
              " 'People',\n",
              " 'airport',\n",
              " 'building',\n",
              " 'fight',\n",
              " 'fine',\n",
              " 'hardly',\n",
              " 'regret',\n",
              " 'situation',\n",
              " 'somewhere',\n",
              " 'suspect',\n",
              " 'Many',\n",
              " 'arrive',\n",
              " 'lawyer',\n",
              " 'least',\n",
              " 'passed',\n",
              " 'stole',\n",
              " 'taken',\n",
              " 'walked',\n",
              " 'Wait',\n",
              " 'bag',\n",
              " 'coat',\n",
              " 'dream',\n",
              " 'helping',\n",
              " 'library',\n",
              " 'medicine',\n",
              " 'opinion',\n",
              " 'others',\n",
              " 'shot',\n",
              " 'showed',\n",
              " 'smoking',\n",
              " 'sometimes',\n",
              " 'weight',\n",
              " 'written',\n",
              " 'Stay',\n",
              " 'apartment',\n",
              " 'bank',\n",
              " 'bring',\n",
              " 'dictionary',\n",
              " 'garden',\n",
              " 'guy',\n",
              " 'immediately',\n",
              " 'joke',\n",
              " 'pictures',\n",
              " 'price',\n",
              " 'quit',\n",
              " 'surprise',\n",
              " 'asking',\n",
              " 'bread',\n",
              " 'color',\n",
              " 'expected',\n",
              " 'forgive',\n",
              " 'front',\n",
              " 'grandfather',\n",
              " 'kissed',\n",
              " 'knife',\n",
              " 'listening',\n",
              " 'noise',\n",
              " 'river',\n",
              " 'allowed',\n",
              " 'arm',\n",
              " 'beach',\n",
              " 'follow',\n",
              " 'leg',\n",
              " 'marry',\n",
              " 'minute',\n",
              " 'noticed',\n",
              " 'real',\n",
              " 'save',\n",
              " 'slept',\n",
              " 'voice',\n",
              " 'agreed',\n",
              " 'chair',\n",
              " 'date',\n",
              " 'pain',\n",
              " 'smoke',\n",
              " 'student',\n",
              " 'boss',\n",
              " 'concert',\n",
              " 'disappointed',\n",
              " 'kid',\n",
              " 'learned',\n",
              " 'pass',\n",
              " 'piano',\n",
              " 'pick',\n",
              " 'poor',\n",
              " 'prefer',\n",
              " 'running',\n",
              " 'seemed',\n",
              " 'solve',\n",
              " 'speaking',\n",
              " 'wake',\n",
              " 'Call',\n",
              " 'address',\n",
              " 'doubt',\n",
              " 'forgotten',\n",
              " 'mad',\n",
              " 'owe',\n",
              " 'smart',\n",
              " 'stolen',\n",
              " 'taught',\n",
              " 'air',\n",
              " 'funny',\n",
              " 'guess',\n",
              " 'necessary',\n",
              " 'protect',\n",
              " 'weeks',\n",
              " 'convinced',\n",
              " 'couple',\n",
              " 'gift',\n",
              " 'girls',\n",
              " 'laugh',\n",
              " 'moment',\n",
              " 'pen',\n",
              " 'plane',\n",
              " 'sign',\n",
              " 'takes',\n",
              " 'vacation',\n",
              " 'As',\n",
              " 'Should',\n",
              " 'also',\n",
              " 'company',\n",
              " 'dogs',\n",
              " 'exam',\n",
              " 'offer',\n",
              " 'played',\n",
              " 'side',\n",
              " 'somebody',\n",
              " 'ticket',\n",
              " 'uncle',\n",
              " 'which',\n",
              " 'blue',\n",
              " 'count',\n",
              " 'four',\n",
              " 'laughing',\n",
              " 'purpose',\n",
              " 'telephone',\n",
              " '20th',\n",
              " 'Nothing',\n",
              " 'bottle',\n",
              " 'future',\n",
              " 'means',\n",
              " 'men',\n",
              " 'nervous',\n",
              " 'perfect',\n",
              " 'radio',\n",
              " 'send',\n",
              " 'wonderful',\n",
              " 'Park',\n",
              " 'apple',\n",
              " 'believed',\n",
              " 'cats',\n",
              " 'expecting',\n",
              " 'women',\n",
              " 'Ca',\n",
              " 'Something',\n",
              " 'Today',\n",
              " 'actually',\n",
              " 'camera',\n",
              " 'hide',\n",
              " 'hiding',\n",
              " 'laughed',\n",
              " 'prove',\n",
              " 'quiet',\n",
              " 'tie',\n",
              " 'Street',\n",
              " 'allow',\n",
              " 'clear',\n",
              " 'danger',\n",
              " 'drank',\n",
              " 'given',\n",
              " 'months',\n",
              " 'pencil',\n",
              " 'report',\n",
              " 'seat',\n",
              " 'shower',\n",
              " 'Show',\n",
              " 'afford',\n",
              " 'bored',\n",
              " 'church',\n",
              " 'decide',\n",
              " 'easily',\n",
              " 'eggs',\n",
              " 'enjoyed',\n",
              " 'movies',\n",
              " 'permission',\n",
              " 'seldom',\n",
              " 'truck',\n",
              " 'watched',\n",
              " 'Am',\n",
              " 'earlier',\n",
              " 'hid',\n",
              " 'information',\n",
              " 'sandwich',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19X2G_QpxJEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ad06678-4460-4b24-8e88-d2e65fb44ecd"
      },
      "source": [
        "target_field.vocab.itos"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<s>',\n",
              " '</s>',\n",
              " '.',\n",
              " ',',\n",
              " 'Том',\n",
              " 'Я',\n",
              " 'не',\n",
              " '?',\n",
              " 'что',\n",
              " 'в',\n",
              " 'это',\n",
              " 'на',\n",
              " 'Ты',\n",
              " 'я',\n",
              " 'с',\n",
              " 'Мэри',\n",
              " 'ты',\n",
              " 'мне',\n",
              " 'Тома',\n",
              " 'Вы',\n",
              " 'меня',\n",
              " 'У',\n",
              " 'Это',\n",
              " 'Мы',\n",
              " 'вы',\n",
              " 'Тому',\n",
              " 'и',\n",
              " 'бы',\n",
              " 'Он',\n",
              " 'сказал',\n",
              " 'Не',\n",
              " 'был',\n",
              " 'чтобы',\n",
              " 'Мне',\n",
              " 'очень',\n",
              " 'тебя',\n",
              " 'тебе',\n",
              " 'у',\n",
              " 'как',\n",
              " 'знаю',\n",
              " 'было',\n",
              " 'так',\n",
              " 'сделать',\n",
              " 'хочу',\n",
              " 'ещё',\n",
              " 'его',\n",
              " 'за',\n",
              " 'есть',\n",
              " 'всё',\n",
              " 'он',\n",
              " 'вам',\n",
              " 'Она',\n",
              " 'знал',\n",
              " 'здесь',\n",
              " 'вас',\n",
              " 'Томом',\n",
              " 'думаю',\n",
              " 'Что',\n",
              " 'о',\n",
              " 'хотел',\n",
              " 'уже',\n",
              " 'нужно',\n",
              " 'Почему',\n",
              " 'этого',\n",
              " 'будет',\n",
              " 'Они',\n",
              " 'могу',\n",
              " 'делать',\n",
              " 'никогда',\n",
              " 'Как',\n",
              " 'из',\n",
              " 'этом',\n",
              " '-',\n",
              " 'больше',\n",
              " 'сделал',\n",
              " 'мы',\n",
              " 'надо',\n",
              " 'нет',\n",
              " 'нас',\n",
              " 'к',\n",
              " 'нам',\n",
              " 'В',\n",
              " 'быть',\n",
              " 'по',\n",
              " 'хочет',\n",
              " 'от',\n",
              " 'об',\n",
              " '!',\n",
              " 'знает',\n",
              " 'её',\n",
              " 'нравится',\n",
              " 'может',\n",
              " 'много',\n",
              " 'ничего',\n",
              " 'была',\n",
              " 'сегодня',\n",
              " 'то',\n",
              " 'для',\n",
              " 'думал',\n",
              " 'должен',\n",
              " 'Тебе',\n",
              " 'ему',\n",
              " 'Бостоне',\n",
              " 'когда',\n",
              " 'Вам',\n",
              " 'до',\n",
              " 'помочь',\n",
              " 'Бостон',\n",
              " 'видел',\n",
              " 'Сколько',\n",
              " 'сказать',\n",
              " 'только',\n",
              " 'все',\n",
              " 'хорошо',\n",
              " 'были',\n",
              " 'ли',\n",
              " 'сейчас',\n",
              " 'со',\n",
              " 'раз',\n",
              " 'говорит',\n",
              " 'три',\n",
              " 'Думаю',\n",
              " 'всегда',\n",
              " 'день',\n",
              " 'пожалуйста',\n",
              " 'чем',\n",
              " 'себя',\n",
              " 'слишком',\n",
              " 'время',\n",
              " 'хочешь',\n",
              " 'Кто',\n",
              " 'Где',\n",
              " 'мог',\n",
              " 'просто',\n",
              " 'тобой',\n",
              " 'Когда',\n",
              " 'Нам',\n",
              " 'лучше',\n",
              " 'дома',\n",
              " 'если',\n",
              " 'мной',\n",
              " 'времени',\n",
              " 'говорил',\n",
              " 'там',\n",
              " 'На',\n",
              " 'же',\n",
              " 'кто',\n",
              " 'эту',\n",
              " 'завтра',\n",
              " 'вчера',\n",
              " 'этот',\n",
              " 'говорить',\n",
              " 'пойти',\n",
              " 'где',\n",
              " 'поговорить',\n",
              " 'домой',\n",
              " 'один',\n",
              " '—',\n",
              " 'хотите',\n",
              " 'почему',\n",
              " '&quot;',\n",
              " 'по-французски',\n",
              " 'идти',\n",
              " 'знаешь',\n",
              " 'что-то',\n",
              " 'буду',\n",
              " 'можешь',\n",
              " 'знать',\n",
              " 'него',\n",
              " 'но',\n",
              " 'Если',\n",
              " 'немного',\n",
              " 'свою',\n",
              " 'туда',\n",
              " 'машину',\n",
              " 'уверен',\n",
              " 'работу',\n",
              " 'Все',\n",
              " 'она',\n",
              " 'должны',\n",
              " 'они',\n",
              " 'денег',\n",
              " 'или',\n",
              " 'вами',\n",
              " 'можете',\n",
              " 'купил',\n",
              " 'лет',\n",
              " 'действительно',\n",
              " 'мой',\n",
              " 'свой',\n",
              " 'люблю',\n",
              " 'Пожалуйста',\n",
              " 'ни',\n",
              " 'Надеюсь',\n",
              " 'этим',\n",
              " 'любит',\n",
              " 'часто',\n",
              " 'себе',\n",
              " 'этой',\n",
              " 'знаете',\n",
              " 'чего',\n",
              " 'раньше',\n",
              " 'такой',\n",
              " 'можем',\n",
              " 'Давай',\n",
              " 'тоже',\n",
              " 'без',\n",
              " 'друг',\n",
              " 'своей',\n",
              " 'сколько',\n",
              " 'Вас',\n",
              " 'Давайте',\n",
              " 'книгу',\n",
              " 'чём',\n",
              " 'несколько',\n",
              " 'Австралии',\n",
              " 'правда',\n",
              " 'Никто',\n",
              " 'почти',\n",
              " 'деньги',\n",
              " 'стоит',\n",
              " 'Мой',\n",
              " 'купить',\n",
              " 'дом',\n",
              " 'том',\n",
              " 'случилось',\n",
              " 'сюда',\n",
              " 'французский',\n",
              " 'Скажи',\n",
              " 'человек',\n",
              " 'знали',\n",
              " 'всего',\n",
              " 'найти',\n",
              " 'ведь',\n",
              " 'их',\n",
              " 'попросил',\n",
              " 'слышал',\n",
              " 'пока',\n",
              " 'свои',\n",
              " 'года',\n",
              " 'С',\n",
              " 'что-нибудь',\n",
              " 'нужна',\n",
              " 'твой',\n",
              " 'Можно',\n",
              " 'Этот',\n",
              " 'дверь',\n",
              " 'сделали',\n",
              " 'когда-нибудь',\n",
              " 'Эта',\n",
              " 'вечером',\n",
              " 'вместе',\n",
              " 'вопрос',\n",
              " 'никто',\n",
              " 'школу',\n",
              " 'рад',\n",
              " 'поехать',\n",
              " 'даже',\n",
              " 'нами',\n",
              " 'а',\n",
              " 'пришёл',\n",
              " 'произошло',\n",
              " 'Меня',\n",
              " 'Моя',\n",
              " 'помощь',\n",
              " 'Его',\n",
              " 'думаешь',\n",
              " 'кофе',\n",
              " 'смог',\n",
              " 'ждать',\n",
              " 'живёт',\n",
              " 'делал',\n",
              " 'правду',\n",
              " 'назад',\n",
              " 'сказали',\n",
              " 'Скажите',\n",
              " 'моя',\n",
              " 'того',\n",
              " 'году',\n",
              " 'работает',\n",
              " 'всех',\n",
              " 'забыл',\n",
              " 'комнате',\n",
              " 'могли',\n",
              " 'отец',\n",
              " 'занят',\n",
              " 'рано',\n",
              " 'можно',\n",
              " 'снова',\n",
              " 'Сегодня',\n",
              " 'делает',\n",
              " 'остаться',\n",
              " 'решил',\n",
              " 'спать',\n",
              " 'письмо',\n",
              " 'Вот',\n",
              " 'нашёл',\n",
              " 'рассказал',\n",
              " 'играть',\n",
              " 'моей',\n",
              " 'Зачем',\n",
              " 'дал',\n",
              " 'работать',\n",
              " 'собой',\n",
              " 'пошёл',\n",
              " 'твоя',\n",
              " 'умер',\n",
              " 'быстро',\n",
              " 'ей',\n",
              " 'куда',\n",
              " 'следует',\n",
              " 'хороший',\n",
              " 'знаем',\n",
              " 'каждый',\n",
              " 'ним',\n",
              " 'перед',\n",
              " 'умеет',\n",
              " 'детей',\n",
              " 'пор',\n",
              " 'во',\n",
              " 'неё',\n",
              " 'через',\n",
              " 'помог',\n",
              " 'Спасибо',\n",
              " 'ваш',\n",
              " 'моего',\n",
              " 'совсем',\n",
              " 'два',\n",
              " 'думаете',\n",
              " 'дождь',\n",
              " 'после',\n",
              " 'эти',\n",
              " 'Можешь',\n",
              " 'По-моему',\n",
              " 'утром',\n",
              " 'спросил',\n",
              " 'тут',\n",
              " 'Интересно',\n",
              " 'будем',\n",
              " 'неделе',\n",
              " 'тот',\n",
              " 'прав',\n",
              " 'Австралию',\n",
              " 'сказала',\n",
              " 'Откуда',\n",
              " 'увидеть',\n",
              " 'говорили',\n",
              " 'стал',\n",
              " 'готов',\n",
              " 'будешь',\n",
              " 'жизнь',\n",
              " 'им',\n",
              " 'оба',\n",
              " 'своего',\n",
              " 'скоро',\n",
              " 'собираюсь',\n",
              " 'уйти',\n",
              " 'сделаю',\n",
              " 'кажется',\n",
              " 'обычно',\n",
              " 'них',\n",
              " 'нужен',\n",
              " 'хотела',\n",
              " 'видеть',\n",
              " 'прийти',\n",
              " 'ушёл',\n",
              " 'эта',\n",
              " 'кое-что',\n",
              " 'мои',\n",
              " 'проблема',\n",
              " 'своё',\n",
              " 'придёт',\n",
              " 'понимаю',\n",
              " 'телевизор',\n",
              " 'трудно',\n",
              " 'этому',\n",
              " 'Теперь',\n",
              " 'жить',\n",
              " 'последний',\n",
              " 'Какой',\n",
              " 'брат',\n",
              " 'ехать',\n",
              " 'людей',\n",
              " 'помощи',\n",
              " 'потерял',\n",
              " 'происходит',\n",
              " 'идея',\n",
              " 'люди',\n",
              " 'своих',\n",
              " 'сам',\n",
              " 'Хочешь',\n",
              " 'достаточно',\n",
              " 'под',\n",
              " 'мою',\n",
              " 'Куда',\n",
              " 'наверное',\n",
              " 'Бостона',\n",
              " 'плавать',\n",
              " 'да',\n",
              " 'сих',\n",
              " 'такая',\n",
              " 'имя',\n",
              " 'кто-то',\n",
              " 'понедельник',\n",
              " 'пытался',\n",
              " 'Просто',\n",
              " 'Всё',\n",
              " 'никого',\n",
              " 'никому',\n",
              " 'одна',\n",
              " 'выглядит',\n",
              " 'думает',\n",
              " 'знают',\n",
              " 'место',\n",
              " 'Здесь',\n",
              " 'друга',\n",
              " 'видели',\n",
              " 'понял',\n",
              " 'сделает',\n",
              " 'Дай',\n",
              " 'тридцать',\n",
              " 'говорю',\n",
              " 'нельзя',\n",
              " 'пришлось',\n",
              " 'смогу',\n",
              " 'вернулся',\n",
              " 'всю',\n",
              " 'долго',\n",
              " 'похоже',\n",
              " 'кем',\n",
              " 'Во',\n",
              " 'книга',\n",
              " 'тем',\n",
              " 'машина',\n",
              " 'начал',\n",
              " 'друзей',\n",
              " 'единственный',\n",
              " 'порядке',\n",
              " 'против',\n",
              " 'Думаешь',\n",
              " 'машине',\n",
              " 'помню',\n",
              " 'придётся',\n",
              " 'Может',\n",
              " 'работа',\n",
              " 'хорошая',\n",
              " 'моё',\n",
              " 'руки',\n",
              " 'зовут',\n",
              " 'оставил',\n",
              " 'прошлой',\n",
              " 'часа',\n",
              " 'взять',\n",
              " 'комнату',\n",
              " 'помогать',\n",
              " 'хотели',\n",
              " 'весь',\n",
              " 'жизни',\n",
              " 'месте',\n",
              " 'должно',\n",
              " 'рассказать',\n",
              " 'своим',\n",
              " 'устал',\n",
              " 'Её',\n",
              " 'подождать',\n",
              " 'работы',\n",
              " 'Можете',\n",
              " 'довольно',\n",
              " 'неделю',\n",
              " 'часов',\n",
              " 'ваша',\n",
              " 'вопросов',\n",
              " 'говорите',\n",
              " 'книги',\n",
              " 'которые',\n",
              " 'читать',\n",
              " 'новый',\n",
              " 'ночью',\n",
              " 'приехал',\n",
              " 'решение',\n",
              " 'сестра',\n",
              " 'Дайте',\n",
              " 'взял',\n",
              " 'дня',\n",
              " 'минут',\n",
              " 'собаку',\n",
              " 'такое',\n",
              " 'всем',\n",
              " 'долларов',\n",
              " 'мать',\n",
              " 'план',\n",
              " 'Томе',\n",
              " 'школе',\n",
              " 'деле',\n",
              " 'написал',\n",
              " 'получил',\n",
              " 'проблемы',\n",
              " 'рождения',\n",
              " 'хотим',\n",
              " 'язык',\n",
              " 'Эти',\n",
              " 'находится',\n",
              " 'нравятся',\n",
              " 'понравится',\n",
              " 'Сейчас',\n",
              " 'вернуться',\n",
              " 'доме',\n",
              " 'кого',\n",
              " 'ходить',\n",
              " 'замуж',\n",
              " 'собака',\n",
              " 'ключи',\n",
              " 'ходил',\n",
              " 'вообще',\n",
              " 'десять',\n",
              " 'знала',\n",
              " 'имеет',\n",
              " 'над',\n",
              " 'пить',\n",
              " 'разговаривать',\n",
              " 'говорят',\n",
              " 'потому',\n",
              " 'сделала',\n",
              " 'твоей',\n",
              " 'ту',\n",
              " 'Есть',\n",
              " 'Хотите',\n",
              " 'будете',\n",
              " 'посмотреть',\n",
              " 'предложение',\n",
              " 'фильм',\n",
              " 'часы',\n",
              " 'Разве',\n",
              " 'большой',\n",
              " 'играет',\n",
              " 'одного',\n",
              " 'окно',\n",
              " 'самом',\n",
              " 'старше',\n",
              " 'теперь',\n",
              " 'ужин',\n",
              " 'чуть',\n",
              " 'делаю',\n",
              " 'прошлом',\n",
              " 'согласен',\n",
              " 'А',\n",
              " 'Какая',\n",
              " 'Чем',\n",
              " 'ко',\n",
              " 'случится',\n",
              " 'счастлив',\n",
              " 'дети',\n",
              " 'доверять',\n",
              " 'должна',\n",
              " 'который',\n",
              " 'подумал',\n",
              " 'сможет',\n",
              " 'собирается',\n",
              " 'чувствую',\n",
              " 'именно',\n",
              " 'кроме',\n",
              " 'могут',\n",
              " 'ней',\n",
              " 'нужны',\n",
              " 'поздно',\n",
              " 'твои',\n",
              " 'точно',\n",
              " 'третьего',\n",
              " 'Возможно',\n",
              " 'Вчера',\n",
              " 'друзья',\n",
              " 'отсюда',\n",
              " 'поесть',\n",
              " 'пять',\n",
              " 'теннис',\n",
              " 'уверена',\n",
              " 'Тебя',\n",
              " 'воды',\n",
              " 'гораздо',\n",
              " 'жил',\n",
              " 'легко',\n",
              " 'любишь',\n",
              " 'столько',\n",
              " 'дело',\n",
              " 'идёт',\n",
              " 'ключ',\n",
              " 'книг',\n",
              " 'лишь',\n",
              " 'отца',\n",
              " 'подарок',\n",
              " 'руку',\n",
              " 'таким',\n",
              " 'заниматься',\n",
              " 'машины',\n",
              " 'номер',\n",
              " 'уехал',\n",
              " 'вижу',\n",
              " 'вопросы',\n",
              " 'думала',\n",
              " 'К',\n",
              " 'Похоже',\n",
              " 'вина',\n",
              " 'ответ',\n",
              " 'поверить',\n",
              " 'понадобится',\n",
              " 'прямо',\n",
              " 'Ему',\n",
              " 'По',\n",
              " 'более',\n",
              " 'вроде',\n",
              " 'ночь',\n",
              " 'улице',\n",
              " 'Могу',\n",
              " 'дней',\n",
              " 'понять',\n",
              " 'совершенно',\n",
              " 'За',\n",
              " 'автобусе',\n",
              " 'вышел',\n",
              " 'зачем',\n",
              " 'опять',\n",
              " 'просил',\n",
              " 'самое',\n",
              " 'спит',\n",
              " 'стол',\n",
              " 'боится',\n",
              " 'видела',\n",
              " 'обратно',\n",
              " 'пойду',\n",
              " 'попросить',\n",
              " 'хотят',\n",
              " 'глаза',\n",
              " 'еще',\n",
              " 'моим',\n",
              " 'нашли',\n",
              " 'нечего',\n",
              " 'поехал',\n",
              " 'телефон',\n",
              " 'Японии',\n",
              " 'выиграть',\n",
              " 'делаешь',\n",
              " 'позвонил',\n",
              " 'положил',\n",
              " 'поможет',\n",
              " 'потом',\n",
              " 'Фома',\n",
              " 'заметил',\n",
              " 'ошибку',\n",
              " 'планирует',\n",
              " 'поезд',\n",
              " 'работе',\n",
              " 'спросить',\n",
              " 'узнал',\n",
              " 'будут',\n",
              " 'говоришь',\n",
              " 'работаю',\n",
              " 'скажу',\n",
              " 'такого',\n",
              " 'твоё',\n",
              " 'тех',\n",
              " 'жду',\n",
              " 'надеюсь',\n",
              " 'ожидал',\n",
              " 'понравилось',\n",
              " 'пора',\n",
              " 'съел',\n",
              " 'холодно',\n",
              " 'Завтра',\n",
              " 'Кто-нибудь',\n",
              " 'автобус',\n",
              " 'вернётся',\n",
              " 'давно',\n",
              " 'две',\n",
              " 'моих',\n",
              " 'опоздал',\n",
              " 'принял',\n",
              " 'раза',\n",
              " 'сел',\n",
              " 'смотреть',\n",
              " 'час',\n",
              " 'другом',\n",
              " 'ел',\n",
              " 'которую',\n",
              " 'любимый',\n",
              " 'одной',\n",
              " 'понятия',\n",
              " 'ребёнок',\n",
              " 'следующей',\n",
              " 'делали',\n",
              " 'из-за',\n",
              " 'объяснить',\n",
              " 'позвонить',\n",
              " 'произойдёт',\n",
              " 'свет',\n",
              " 'шесть',\n",
              " 'Простите',\n",
              " 'выиграет',\n",
              " 'дать',\n",
              " 'любите',\n",
              " 'сильно',\n",
              " 'увидел',\n",
              " 'Кто-то',\n",
              " 'другой',\n",
              " 'имею',\n",
              " 'редко',\n",
              " 'уверены',\n",
              " 'Было',\n",
              " 'Прости',\n",
              " 'вещи',\n",
              " 'красивая',\n",
              " 'О',\n",
              " 'Так',\n",
              " 'Чего',\n",
              " 'брата',\n",
              " 'ваши',\n",
              " 'вид',\n",
              " 'волосы',\n",
              " 'другу',\n",
              " 'посмотрел',\n",
              " 'про',\n",
              " 'тогда',\n",
              " 'Думаете',\n",
              " 'Никогда',\n",
              " 'говори',\n",
              " 'год',\n",
              " 'женат',\n",
              " 'закончил',\n",
              " 'любят',\n",
              " 'петь',\n",
              " 'пешком',\n",
              " 'родители',\n",
              " 'спал',\n",
              " 'утро',\n",
              " 'чего-нибудь',\n",
              " 'важно',\n",
              " 'выйти',\n",
              " 'какой',\n",
              " 'одно',\n",
              " 'одному',\n",
              " 'одну',\n",
              " 'понимает',\n",
              " 'попробовать',\n",
              " 'правильно',\n",
              " 'родился',\n",
              " 'убить',\n",
              " 'хотелось',\n",
              " 'безопасности',\n",
              " 'намного',\n",
              " 'октября',\n",
              " 'половине',\n",
              " 'работал',\n",
              " 'Кажется',\n",
              " 'виду',\n",
              " 'вовремя',\n",
              " 'знаком',\n",
              " 'около',\n",
              " 'остановить',\n",
              " 'плохо',\n",
              " 'пришла',\n",
              " 'самый',\n",
              " 'сообщение',\n",
              " 'такси',\n",
              " 'твоего',\n",
              " 'хочется',\n",
              " 'Ваш',\n",
              " 'вероятно',\n",
              " 'возможно',\n",
              " 'выходные',\n",
              " 'заняты',\n",
              " 'новую',\n",
              " 'отказался',\n",
              " 'открыл',\n",
              " 'парень',\n",
              " 'удивлён',\n",
              " 'Какое',\n",
              " 'То',\n",
              " 'водить',\n",
              " 'встретил',\n",
              " 'выиграл',\n",
              " 'девушка',\n",
              " 'ездил',\n",
              " 'кто-нибудь',\n",
              " 'оставить',\n",
              " 'первый',\n",
              " 'поэтому',\n",
              " 'рядом',\n",
              " 'той',\n",
              " 'умею',\n",
              " 'цветы',\n",
              " 'Нет',\n",
              " 'Ни',\n",
              " 'Оно',\n",
              " 'большая',\n",
              " 'городе',\n",
              " 'дела',\n",
              " 'ждёт',\n",
              " 'наш',\n",
              " 'обо',\n",
              " 'ответил',\n",
              " 'ответить',\n",
              " 'пришли',\n",
              " 'рада',\n",
              " 'смотрел',\n",
              " 'сын',\n",
              " 'такие',\n",
              " 'хватает',\n",
              " 'Лучше',\n",
              " 'Некоторые',\n",
              " 'город',\n",
              " 'готовы',\n",
              " 'живу',\n",
              " 'неправильно',\n",
              " 'примерно',\n",
              " 'следовало',\n",
              " 'вашей',\n",
              " 'велосипед',\n",
              " 'воду',\n",
              " 'выглядишь',\n",
              " 'выше',\n",
              " 'интересно',\n",
              " 'курить',\n",
              " 'обе',\n",
              " 'показал',\n",
              " 'решить',\n",
              " 'ваше',\n",
              " 'имел',\n",
              " 'нашей',\n",
              " 'оставаться',\n",
              " 'очки',\n",
              " 'песню',\n",
              " 'победит',\n",
              " 'принёс',\n",
              " 'разве',\n",
              " 'сидел',\n",
              " 'стать',\n",
              " 'уроки',\n",
              " 'французском',\n",
              " 'И',\n",
              " 'Этого',\n",
              " 'бросил',\n",
              " 'вернусь',\n",
              " 'вечеринку',\n",
              " 'вышла',\n",
              " 'говорила',\n",
              " 'делают',\n",
              " 'едва',\n",
              " 'ест',\n",
              " 'закончить',\n",
              " 'кого-нибудь',\n",
              " 'между',\n",
              " 'музыку',\n",
              " 'помогу',\n",
              " 'прощения',\n",
              " 'равно',\n",
              " 'сесть',\n",
              " 'следующем',\n",
              " 'следующий',\n",
              " 'делаете',\n",
              " 'еду',\n",
              " 'жена',\n",
              " 'классе',\n",
              " 'мама',\n",
              " 'правы',\n",
              " 'сама',\n",
              " 'собираетесь',\n",
              " 'узнать',\n",
              " 'украл',\n",
              " 'цвет',\n",
              " 'чай',\n",
              " 'читал',\n",
              " 'Боюсь',\n",
              " 'Люди',\n",
              " 'болит',\n",
              " 'верю',\n",
              " 'ждал',\n",
              " 'занята',\n",
              " 'купили',\n",
              " 'недели',\n",
              " 'похож',\n",
              " 'скажи',\n",
              " 'Какие',\n",
              " 'Многие',\n",
              " 'купила',\n",
              " 'оно',\n",
              " 'осталось',\n",
              " 'планы',\n",
              " 'снег',\n",
              " 'стоило',\n",
              " 'твою',\n",
              " 'человека',\n",
              " 'Дети',\n",
              " 'Ну',\n",
              " 'верить',\n",
              " 'внимания',\n",
              " 'голос',\n",
              " 'дальше',\n",
              " 'друзьями',\n",
              " 'еды',\n",
              " 'значит',\n",
              " 'зонтик',\n",
              " 'комнаты',\n",
              " 'мало',\n",
              " 'починить',\n",
              " 'права',\n",
              " 'смерти',\n",
              " 'ходит',\n",
              " 'встал',\n",
              " 'дочь',\n",
              " 'женщина',\n",
              " 'задать',\n",
              " 'историю',\n",
              " 'надеялся',\n",
              " 'парке',\n",
              " 'платье',\n",
              " 'принять',\n",
              " 'слова',\n",
              " 'сына',\n",
              " 'уехать',\n",
              " 'Ваша',\n",
              " 'Джон',\n",
              " 'далеко',\n",
              " 'иногда',\n",
              " 'никаких',\n",
              " 'пальто',\n",
              " 'спасибо',\n",
              " 'умеешь',\n",
              " 'французского',\n",
              " 'Ей',\n",
              " 'Полиция',\n",
              " 'Расскажи',\n",
              " 'будь',\n",
              " 'дам',\n",
              " 'коробку',\n",
              " 'месяце',\n",
              " 'мнение',\n",
              " 'моложе',\n",
              " 'писать',\n",
              " 'рыбалку',\n",
              " 'сложно',\n",
              " 'телефона',\n",
              " 'улицу',\n",
              " 'экзамен',\n",
              " 'Больше',\n",
              " 'Зря',\n",
              " 'дерево',\n",
              " 'искал',\n",
              " 'могла',\n",
              " 'одолжить',\n",
              " 'позволить',\n",
              " 'слово',\n",
              " 'собираешься',\n",
              " 'согласился',\n",
              " 'странно',\n",
              " 'тому',\n",
              " 'выпить',\n",
              " 'играл',\n",
              " 'немедленно',\n",
              " 'открыть',\n",
              " 'первым',\n",
              " 'пошли',\n",
              " 'скорее',\n",
              " 'смотрит',\n",
              " 'столе',\n",
              " ':',\n",
              " 'Будь',\n",
              " 'Для',\n",
              " 'Мои',\n",
              " 'Твой',\n",
              " 'быстрее',\n",
              " 'вести',\n",
              " 'выглядел',\n",
              " 'звонил',\n",
              " 'канадец',\n",
              " 'лекарство',\n",
              " 'мире',\n",
              " 'молод',\n",
              " 'недостаточно',\n",
              " 'окна',\n",
              " 'победить',\n",
              " 'позже',\n",
              " 'прежде',\n",
              " 'услышал',\n",
              " 'уходить',\n",
              " 'хожу',\n",
              " 'шляпу',\n",
              " 'Ничего',\n",
              " 'врач',\n",
              " 'вряд',\n",
              " 'голоден',\n",
              " 'имени',\n",
              " 'ошибок',\n",
              " 'поговорим',\n",
              " 'пообещал',\n",
              " 'проблему',\n",
              " 'провёл',\n",
              " 'рассказывал',\n",
              " 'решили',\n",
              " 'сразу',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FYJe2CA8GcY",
        "colab_type": "text"
      },
      "source": [
        "## Seq2seq модель\n",
        "\n",
        "Пора писать простой seq2seq. Разобьем модель на несколько модулей - Encoder, Decoder и их объединение. \n",
        "\n",
        "Encoder должен быть подобен символьной сеточке в POS tagging'е: эмбеддить токены и запускать rnn'ку (в данном случае будем пользоваться GRU) и отдавать последнее скрытое состояние.\n",
        "\n",
        "Decoder почти такой же, только еще и предсказывает токены на каждом своем шаге.\n",
        "\n",
        "**Задание** Реализовать модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySJ4tUAqvFvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJRsBLSlnllw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "523c5d2d-37dd-48a0-88ce-3a349d03ebe5"
      },
      "source": [
        "batch.target.shape[1]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NjlLnrWO-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256,\n",
        "                 num_layers=1, bidirectional=False, debag=False):\n",
        "        super().__init__()\n",
        "        self.debag = debag\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                           num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        emb = self._emb(inputs)\n",
        "        out, hidden = self._rnn(emb)\n",
        "\n",
        "        if self.debag == True:\n",
        "            print('---Encoder start---')\n",
        "            print(f'ENCODER inputs shape: {inputs.shape}')\n",
        "            print(f'ENCODEE emb shape: {emb.shape}')\n",
        "            print(f'ENCODER hidden shape: {hidden.shape}')\n",
        "            print(f'ENCODER output shape: {out.shape}')\n",
        "            print('---End Encoder---')\n",
        "            print(' ')\n",
        "\n",
        "        return out, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0AOmdqLPp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1, debag=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.debag = debag\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, encoder_output, hidden=None):\n",
        "        emb = self._emb(inputs)\n",
        "        outputs = []\n",
        "        if self.debag == True:\n",
        "            print('---Start Decoder---')\n",
        "            print(f'DECODER emb.shape: {emb.shape}')\n",
        "            print('---End Decoder---')\n",
        "            print(' ')\n",
        "\n",
        "        for i in range(emb.shape[0]):\n",
        "            out, hidden = self._rnn(emb[i: i+1], hidden)\n",
        "            outputs.append(out)\n",
        "\n",
        "        output = torch.cat(outputs)\n",
        "\n",
        "        return self._out(output), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9nsO1HCmgn3",
        "colab_type": "text"
      },
      "source": [
        "Модель перевода будет просто сперва вызывать Encoder, а потом передавать его скрытое состояние декодеру в качестве начального."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIGjPOiO7X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=128, \n",
        "                 rnn_hidden_dim=256, num_layers=1, bidirectional_encoder=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers, bidirectional_encoder)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, num_layers)\n",
        "        \n",
        "    def forward(self, source_inputs, target_inputs):\n",
        "        _, encoder_hidden = self.encoder(source_inputs)\n",
        "        \n",
        "        return self.decoder(target_inputs, encoder_hidden, encoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_qVuSL8QJg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4200eff7-39a2-4625-8e3b-8c13ab815255"
      },
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "res = model(batch.source, batch.target)\n",
        "res[0].shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 32, 11231])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz4Ckgh1mwm4",
        "colab_type": "text"
      },
      "source": [
        "Реализуем простой перевод - жадный. На каждом шаге будем выдавать самый вероятный из предсказываемых токенов:\n",
        "\n",
        "![](https://github.com/tensorflow/nmt/raw/master/nmt/g3doc/img/greedy_dec.jpg)  \n",
        "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
        "\n",
        "**Задание** Реализовать функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9gmcOC9DwiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_decode(model, source_text, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result = [] # list of predicted tokens indices\n",
        "        text = source_field.preprocess(source_text)\n",
        "        tokens = [bos_index] + text + [eos_index]\n",
        "\n",
        "        source_indexes = [source_field.vocab.stoi[token] for token in tokens]\n",
        "        source_tensor = torch.LongTensor(source_indexes).unsqueeze(1).to(DEVICE)\n",
        "\n",
        "\n",
        "        encoder_outputs, encoder_hidden = model.encoder(source_tensor)\n",
        "\n",
        "        hidden = encoder_hidden\n",
        "\n",
        "        result = [bos_index]\n",
        "\n",
        "\n",
        "        for _ in range(50):  #пальцем в небо\n",
        "            target_tensor = torch.LongTensor([result[-1]]).to(DEVICE)\n",
        "            #print(f'result shape: {result.shape}, result type: {type(result)}, value: {result}')\n",
        "            output, hidden = model.decoder(target_tensor.unsqueeze(1), encoder_outputs, hidden)\n",
        "\n",
        "            pred_token = output.argmax(-1)\n",
        "\n",
        "            result.append(pred_token)\n",
        "            if pred_token == eos_index:\n",
        "                break\n",
        "\n",
        "            \n",
        "        return ' '.join(target_field.vocab.itos[ind] for ind in result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM58pAd6FBml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7298a629-fb0f-41c0-91d9-05491624035e"
      },
      "source": [
        "greedy_decode(model, \"Do you believe?\", source_field, target_field)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> арестовала прочту прочту виноватым души губам сосредоточиться догнать красные маленькой перестань службу доску острову собакой имён доску существование сконцентрироваться курите Умоляю составляет едим синяк нами следует озеро считаю Те было Весьма женой горами предоставить несколько братом убью отец учёный дадим костюме законопроект суров рыбачить компромисс поднимался бледная непредсказуем секрета ужина'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ha7DI_ngAO",
        "colab_type": "text"
      },
      "source": [
        "Нужно как-то оценивать модель.\n",
        "\n",
        "Обычно для этого используется [BLEU скор](https://en.wikipedia.org/wiki/BLEU) - что-то вроде точности угадывания n-gram из правильного (референсного) перевода.\n",
        "\n",
        "**Задание** Реализовать функцию оценки: для батчей из `iterator` предсказать их переводы, обрезать по `</s>` и сложить правильные варианты и предсказанные в `refs` и `hyps` соответственно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjYA3eohGlOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_model(model, iterator):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "    eos_index = iterator.dataset.fields['target'].vocab.stoi[EOS_TOKEN]\n",
        "    bos_index = iterator.dataset.fields['target'].vocab.stoi[BOS_TOKEN]\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            encoder_output, encoder_hidden = model.encoder(batch.source)\n",
        "\n",
        "            hidden = encoder_hidden\n",
        "            result = [LongTensor([bos_index]).expand(1, batch.target.shape[1])]\n",
        "\n",
        "            for _ in range(30):\n",
        "                out, hidden = model.decoder(result[-1], encoder_output, hidden)\n",
        "                out = out.argmax(-1)\n",
        "                result.append(out)\n",
        "\n",
        "            targets = batch.target.data.cpu().numpy().T\n",
        "            eos_indices = (targets == eos_index).argmax(-1)\n",
        "            eos_indices[eos_indices == 0] = targets.shape[1]\n",
        "\n",
        "            targets = [target[:eos_ind] for eos_ind, target in zip(eos_indices, targets)]\n",
        "            refs.extend(targets)\n",
        "            \n",
        "            result = torch.cat(result)\n",
        "            result = result.data.cpu().numpy().T\n",
        "            eos_indices = (result == eos_index).argmax(-1)\n",
        "            eos_indices[eos_indices == 0] = result.shape[1]\n",
        "\n",
        "            result = [res[:eos_ind] for eos_ind, res in zip(eos_indices, result)]\n",
        "            hyps.extend(result)\n",
        "            \n",
        "    return corpus_bleu([[ref] for ref in refs], hyps) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb6z0Z1AXzoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):                \n",
        "                logits, _ = model(batch.source, batch.target)\n",
        "                \n",
        "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
        "            print('\\nVal BLEU = {:.2f}'.format(evaluate_model(model, val_iter)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X2kYDU_rCjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e161db-7087-4194-90bd-281af50032e4"
      },
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 3.25464, PPX = 25.91: 100%|██████████| 3019/3019 [00:59<00:00, 50.33it/s]\n",
            "[1 / 30]   Val: Loss = 2.46366, PPX = 11.75: 100%|██████████| 67/67 [00:01<00:00, 41.77it/s]\n",
            "[2 / 30] Train: Loss = 2.58317, PPX = 13.24:   0%|          | 4/3019 [00:00<06:46,  7.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 20.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 2.05716, PPX = 7.82: 100%|██████████| 3019/3019 [01:00<00:00, 50.24it/s]\n",
            "[2 / 30]   Val: Loss = 1.97256, PPX = 7.19: 100%|██████████| 67/67 [00:01<00:00, 41.60it/s]\n",
            "[3 / 30] Train: Loss = 1.21431, PPX = 3.37:   0%|          | 4/3019 [00:00<06:24,  7.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 26.07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 1.55043, PPX = 4.71: 100%|██████████| 3019/3019 [00:59<00:00, 50.53it/s]\n",
            "[3 / 30]   Val: Loss = 1.78308, PPX = 5.95: 100%|██████████| 67/67 [00:01<00:00, 42.07it/s]\n",
            "[4 / 30] Train: Loss = 1.11877, PPX = 3.06:   0%|          | 4/3019 [00:00<06:25,  7.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 28.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 30] Train: Loss = 1.23734, PPX = 3.45: 100%|██████████| 3019/3019 [00:59<00:00, 50.48it/s]\n",
            "[4 / 30]   Val: Loss = 1.70489, PPX = 5.50: 100%|██████████| 67/67 [00:01<00:00, 41.63it/s]\n",
            "[5 / 30] Train: Loss = 1.17635, PPX = 3.24:   0%|          | 3/3019 [00:00<06:34,  7.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 30.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 30] Train: Loss = 1.02296, PPX = 2.78: 100%|██████████| 3019/3019 [00:59<00:00, 50.57it/s]\n",
            "[5 / 30]   Val: Loss = 1.67308, PPX = 5.33: 100%|██████████| 67/67 [00:01<00:00, 42.14it/s]\n",
            "[6 / 30] Train: Loss = 0.59429, PPX = 1.81:   0%|          | 4/3019 [00:00<07:04,  7.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 31.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 30] Train: Loss = 0.86771, PPX = 2.38: 100%|██████████| 3019/3019 [01:00<00:00, 50.26it/s]\n",
            "[6 / 30]   Val: Loss = 1.67386, PPX = 5.33: 100%|██████████| 67/67 [00:01<00:00, 42.10it/s]\n",
            "[7 / 30] Train: Loss = 0.56707, PPX = 1.76:   0%|          | 4/3019 [00:00<06:12,  8.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 30] Train: Loss = 0.75281, PPX = 2.12: 100%|██████████| 3019/3019 [01:00<00:00, 50.24it/s]\n",
            "[7 / 30]   Val: Loss = 1.69411, PPX = 5.44: 100%|██████████| 67/67 [00:01<00:00, 41.84it/s]\n",
            "[8 / 30] Train: Loss = 0.46208, PPX = 1.59:   0%|          | 5/3019 [00:00<06:02,  8.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 30] Train: Loss = 0.66437, PPX = 1.94: 100%|██████████| 3019/3019 [00:59<00:00, 50.54it/s]\n",
            "[8 / 30]   Val: Loss = 1.72043, PPX = 5.59: 100%|██████████| 67/67 [00:01<00:00, 41.93it/s]\n",
            "[9 / 30] Train: Loss = 0.55334, PPX = 1.74:   0%|          | 4/3019 [00:00<06:06,  8.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 30] Train: Loss = 0.59587, PPX = 1.81: 100%|██████████| 3019/3019 [01:00<00:00, 50.10it/s]\n",
            "[9 / 30]   Val: Loss = 1.75273, PPX = 5.77: 100%|██████████| 67/67 [00:01<00:00, 42.46it/s]\n",
            "[10 / 30] Train: Loss = 0.48334, PPX = 1.62:   0%|          | 4/3019 [00:00<06:28,  7.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 30] Train: Loss = 0.54108, PPX = 1.72: 100%|██████████| 3019/3019 [01:00<00:00, 50.28it/s]\n",
            "[10 / 30]   Val: Loss = 1.78997, PPX = 5.99: 100%|██████████| 67/67 [00:01<00:00, 41.98it/s]\n",
            "[11 / 30] Train: Loss = 0.51771, PPX = 1.68:   0%|          | 4/3019 [00:00<06:08,  8.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 30] Train: Loss = 0.49869, PPX = 1.65: 100%|██████████| 3019/3019 [00:59<00:00, 50.34it/s]\n",
            "[11 / 30]   Val: Loss = 1.82426, PPX = 6.20: 100%|██████████| 67/67 [00:01<00:00, 42.70it/s]\n",
            "[12 / 30] Train: Loss = 0.36457, PPX = 1.44:   0%|          | 4/3019 [00:00<06:11,  8.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[12 / 30] Train: Loss = 0.46309, PPX = 1.59: 100%|██████████| 3019/3019 [01:00<00:00, 49.56it/s]\n",
            "[12 / 30]   Val: Loss = 1.86903, PPX = 6.48: 100%|██████████| 67/67 [00:01<00:00, 42.52it/s]\n",
            "[13 / 30] Train: Loss = 0.25649, PPX = 1.29:   0%|          | 4/3019 [00:00<06:04,  8.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[13 / 30] Train: Loss = 0.43232, PPX = 1.54: 100%|██████████| 3019/3019 [01:00<00:00, 49.57it/s]\n",
            "[13 / 30]   Val: Loss = 1.90647, PPX = 6.73: 100%|██████████| 67/67 [00:01<00:00, 43.51it/s]\n",
            "[14 / 30] Train: Loss = 0.39835, PPX = 1.49:   0%|          | 4/3019 [00:00<06:06,  8.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[14 / 30] Train: Loss = 0.40913, PPX = 1.51: 100%|██████████| 3019/3019 [01:00<00:00, 49.94it/s]\n",
            "[14 / 30]   Val: Loss = 1.94451, PPX = 6.99: 100%|██████████| 67/67 [00:01<00:00, 41.53it/s]\n",
            "[15 / 30] Train: Loss = 0.29651, PPX = 1.35:   0%|          | 4/3019 [00:00<06:14,  8.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[15 / 30] Train: Loss = 0.38683, PPX = 1.47: 100%|██████████| 3019/3019 [01:00<00:00, 49.84it/s]\n",
            "[15 / 30]   Val: Loss = 1.98463, PPX = 7.28: 100%|██████████| 67/67 [00:01<00:00, 42.42it/s]\n",
            "[16 / 30] Train: Loss = 0.37004, PPX = 1.45:   0%|          | 4/3019 [00:00<06:16,  8.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[16 / 30] Train: Loss = 0.37006, PPX = 1.45: 100%|██████████| 3019/3019 [01:00<00:00, 49.56it/s]\n",
            "[16 / 30]   Val: Loss = 2.01124, PPX = 7.47: 100%|██████████| 67/67 [00:01<00:00, 42.47it/s]\n",
            "[17 / 30] Train: Loss = 0.20562, PPX = 1.23:   0%|          | 4/3019 [00:00<06:27,  7.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[17 / 30] Train: Loss = 0.35596, PPX = 1.43: 100%|██████████| 3019/3019 [01:01<00:00, 49.24it/s]\n",
            "[17 / 30]   Val: Loss = 2.04829, PPX = 7.75: 100%|██████████| 67/67 [00:01<00:00, 42.21it/s]\n",
            "[18 / 30] Train: Loss = 0.27142, PPX = 1.31:   0%|          | 4/3019 [00:00<06:21,  7.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[18 / 30] Train: Loss = 0.34108, PPX = 1.41: 100%|██████████| 3019/3019 [01:01<00:00, 48.96it/s]\n",
            "[18 / 30]   Val: Loss = 2.08409, PPX = 8.04: 100%|██████████| 67/67 [00:01<00:00, 43.59it/s]\n",
            "[19 / 30] Train: Loss = 0.26123, PPX = 1.30:   0%|          | 4/3019 [00:00<06:48,  7.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.77\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[19 / 30] Train: Loss = 0.32991, PPX = 1.39: 100%|██████████| 3019/3019 [01:01<00:00, 49.01it/s]\n",
            "[19 / 30]   Val: Loss = 2.11280, PPX = 8.27: 100%|██████████| 67/67 [00:01<00:00, 42.30it/s]\n",
            "[20 / 30] Train: Loss = 0.28142, PPX = 1.33:   0%|          | 4/3019 [00:00<06:12,  8.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[20 / 30] Train: Loss = 0.26322, PPX = 1.30:   7%|▋         | 209/3019 [00:04<00:57, 49.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZQPnu2KfSJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29114be0-464e-4336-bdbe-41a006dbfe25"
      },
      "source": [
        "greedy_decode(model, \"Do you believe?\", source_field, target_field)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Кому ты выучил ? </s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es0D28m5jdNF",
        "colab_type": "text"
      },
      "source": [
        "## Scheduled Sampling\n",
        "\n",
        "До сих пор мы тренировали перевод, используя так называемый *teacher forcing*: в качестве выхода на предыдущем шаге декодер принимал всегда правильный токен. Проблема такого подхода - во время инференса правильный токен, скорее всего, не выберется хотя бы на каком-то шаге. Получится, что сеть училась на хороших входах, использоваться будет на плохом - это легко может всё поломать.\n",
        "\n",
        "Альтернативный подход - прямо во время обучения сэмплировать токен с текущего шага и передавать его на следующий.\n",
        "\n",
        "Такой подход не слишком-то обоснован математически (градиенты не прокидываются через сэмплирование), но его интересно реализовать и он зачастую улучшает качество.\n",
        "\n",
        "**Задание** Обновите `Decoder`: замените вызов rnn'ки над последовательностью на цикл. На каждом шаге вероятностью `p` передавайте в качестве предыдущего выхода декодеру правильный вход, а иначе - argmax от предыдущего выхода (цикл должен быть похожим на те, которые есть в `greedy_decode` и `evaluate_model`). При передаче argmax вызывайте `detach`, чтобы градиенты не прокидывались. Все выходы собирайте в список, в конце сделайте `torch.cat`. \n",
        "\n",
        "В результате при вероятности, равной `p=1`, должно получиться как раньше, только медленнее. При обучении можно передавать `p=0.5`, на инференсе - `p=1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILPhSHsLoGzd",
        "colab_type": "text"
      },
      "source": [
        "## Beam Search\n",
        "\n",
        "Другой способ бороться с ошибками в декодировании на инференсе - делать beam search. По сути это поиск в глубину с очень сильными отсечениями на каждом шаге:\n",
        "\n",
        "![](https://image.ibb.co/dBRKkA/2018-11-06-13-53-40.png)   \n",
        "*From [cs224n, Machine Translation, Seq2Seq and Attention](http://web.stanford.edu/class/cs224n/lectures/lecture10.pdf)*\n",
        "\n",
        "На картинке на каждом шаге выбирается два лучших (согласно предсказаниям сети) из четырех вариантов продолжений цепочек.\n",
        "\n",
        "Для сравнения бимов используются суммы log-вероятностей токенов, входящих в бим. Чтобы получить log-вероятности, нужно просто вызвать `F.log_softmax` у логитов. Преимущество сложения логарифмов перед умножением вероятностей должно быть понятно: нет таких проблем с численной неустойчивостью - умножая вероятности, близкие к нулю, мы очень шустро получим ноль в качестве скора бима.\n",
        "\n",
        "В итоге нужно реализовать аналог `gready_decoding`. \n",
        "\n",
        "Beam будет состоять из последовательности индексов токенов (в начале - `[bos_index]`),  суммарного качества (в начале 0) и последнего `hidden` (в начале `encoder_hidden`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVFK1mGD-FVQ",
        "colab_type": "text"
      },
      "source": [
        "Интерактивная визуализация, утащенная у https://github.com/yandexdataschool/nlp_course:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6vnrGBI-ETr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5035df57-5e80-411f-825e-3751c90b88c5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/beam_search.html 2> log\n",
        "from IPython.display import HTML\n",
        "# source: parlament does not support the amendment freeing tymoshenko\n",
        "HTML('./beam_search.html')"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <meta charset=\"utf-8\">\n",
              "        <title>Bokeh Plot</title>\n",
              "        \n",
              "<link rel=\"stylesheet\" href=\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\" type=\"text/css\" />\n",
              "        \n",
              "<script type=\"text/javascript\" src=\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\"></script>\n",
              "<script type=\"text/javascript\">\n",
              "    Bokeh.set_log_level(\"info\");\n",
              "</script>\n",
              "        <style>\n",
              "          html {\n",
              "            width: 100%;\n",
              "            height: 100%;\n",
              "          }\n",
              "          body {\n",
              "            width: 90%;\n",
              "            height: 100%;\n",
              "            margin: auto;\n",
              "          }\n",
              "        </style>\n",
              "    </head>\n",
              "    <body>\n",
              "        \n",
              "        <div class=\"bk-root\">\n",
              "            <div class=\"bk-plotdiv\" id=\"ff8c3f31-952d-4c2f-8b58-13e7cec51b58\"></div>\n",
              "        </div>\n",
              "        \n",
              "        <script type=\"text/javascript\">\n",
              "            (function() {\n",
              "          var fn = function() {\n",
              "            Bokeh.safely(function() {\n",
              "              var docs_json = {\"ba84f797-d201-498d-a731-5adafa5447b7\":{\"roots\":{\"references\":[{\"attributes\":{\"plot\":null,\"text\":\"Beam search\"},\"id\":\"5af81591-5793-4721-a459-e0a4ca700855\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"43ae4eb3-d229-4335-a758-a5d18149bd65\",\"type\":\"Circle\"},{\"attributes\":{\"bounds\":[-10.0,20.0],\"callback\":null,\"end\":12,\"js_property_callbacks\":{\"change:end\":[{\"id\":\"eab13fb4-9405-4d14-8bf6-46c6f698b4bb\",\"type\":\"CustomJS\"}]},\"start\":-1},\"id\":\"14e9976c-9458-4bce-be96-da2f3c304cec\",\"type\":\"Range1d\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"2e9dcf01-3f79-4337-b7dd-26f0525180b9\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"08bbcb52-00b5-4803-9e7a-9252db09708d\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"tokens\",\"nonselection_glyph\":{\"id\":\"3621fd59-3cb3-4305-8802-6f7f75a23fd6\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"ddf587aa-019f-43a1-af8c-52144e732785\",\"type\":\"CDSView\"}},\"id\":\"a2ab1853-0966-4519-874f-956f801f1c72\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"id\",\"parent_id\",\"children_ids\",\"is_best\",\"depth\",\"hypo_i\",\"token\",\"token_id\",\"x\",\"y\",\"circle_fill_color\",\"line_color\",\"line_width\",\"edge_xx\",\"edge_yy\",\"token_text\",\"token_font_size\",\"hypo_i_text\",\"hypo_i_offset\",\"_on_hover_token\",\"_on_hover_token_id\",\"_on_hover_score\"],\"data\":{\"_on_hover_score\":[\"-4.7282\",\"-4.2071\",\"-4.8782\",\"-1.3577\",\"-4.0420\",\"-4.2097\",\"-4.5624\",\"-3.2410\",\"-6.9225\",\"-4.6717\",\"-2.8497\",\"-3.8023\",\"-4.1460\",\"-3.6443\",\"-4.3135\",\"-4.7070\",\"-3.1373\",\"-4.5105\",\"-6.1526\",\"-3.0974\",\"-3.7421\",\"-3.4956\",\"0.0000\",\"-5.2694\",\"-4.4104\",\"-6.1752\",\"-3.7617\",\"-4.6281\",\"-6.5626\",\"-3.7175\",\"-0.7384\",\"-4.5439\",\"-5.2967\",\"-3.6831\",\"-5.2153\",\"-3.7830\",\"-3.1335\",\"-0.8716\",\"-3.7312\",\"-3.8895\",\"-6.5984\"],\"_on_hover_token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"_on_hover_token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"children_ids\":[[],[[2,3]],[[10,3],[10,2],[10,1],[10,0]],[[4,3],[4,1],[4,0]],[[9,3],[9,1],[9,0]],[],[],[[6,1]],[],[[8,2]],[[5,0]],[[2,2]],[],[[4,2]],[],[[7,2]],[[6,2],[6,0]],[],[],[[5,1]],[[2,1]],[],[[1,3],[1,2],[1,1],[1,0]],[[9,2]],[[8,1]],[],[[7,3],[7,1]],[],[],[[5,2]],[[2,0]],[],[],[[8,3],[8,0]],[],[[7,0]],[],[[3,3],[3,2],[3,1],[3,0]],[[5,3]],[[6,3]],[]],\"circle_fill_color\":[\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\"],\"depth\":[7,1,9,3,8,2,6,5,10,7,4,1,9,3,8,6,5,2,10,4,1,3,0,8,7,9,6,2,10,4,1,5,8,7,9,6,3,2,4,5,10],\"edge_xx\":[[6.0,7.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[1.0,2.0],[5.0,6.0],[4.0,5.0],[9.0,10.0],[6.0,7.0],[3.0,4.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[5.0,6.0],[4.0,5.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[2.0,3.0],[0.0,0.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[4.0,5.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[2.0,3.0],[1.0,2.0],[3.0,4.0],[4.0,5.0],[9.0,10.0]],\"edge_yy\":[[4.833333333333333,4.333333333333333],[0.0,-1.5],[3.333333333333333,3.333333333333333],[1.5,3.0],[2.833333333333333,3.333333333333333],[0.5,0.5],[4.333333333333333,3.833333333333333],[2.833333333333333,2.833333333333333],[3.333333333333333,1.833333333333333],[0.0,0.0],[3.0,4.333333333333333],[0.0,-0.5],[3.333333333333333,4.333333333333333],[1.5,0.0],[5.333333333333333,5.333333333333333],[0.0,0.0],[4.333333333333333,4.333333333333333],[-0.5,-0.5],[3.333333333333333,4.833333333333333],[3.0,2.833333333333333],[0.0,0.5],[1.5,1.0],[0.0,0.0],[0.0,0.0],[4.833333333333333,5.333333333333333],[3.333333333333333,2.333333333333333],[4.333333333333333,4.833333333333333],[-1.5,-1.5],[3.333333333333333,3.833333333333333],[0.0,0.0],[0.0,1.5],[1.8333333333333333,1.8333333333333333],[2.833333333333333,2.333333333333333],[2.833333333333333,2.833333333333333],[0.0,0.0],[2.833333333333333,2.833333333333333],[1.5,2.0],[1.5,1.5],[3.0,1.8333333333333333],[0.0,0.0],[3.333333333333333,2.833333333333333]],\"hypo_i\":[3,3,1,0,0,1,2,1,3,2,0,2,0,3,1,3,0,2,0,1,1,2,0,2,1,3,0,3,1,2,0,3,3,0,2,1,1,0,3,2,2],\"hypo_i_offset\":[-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8],\"hypo_i_text\":[\"#3\",\"#3\",\"#1\",\"#0\",\"#0\",\"#1\",\"#2\",\"#1\",\"#3\",\"#2\",\"#0\",\"#2\",\"#0\",\"#3\",\"#1\",\"#3\",\"#0\",\"#2\",\"#0\",\"#1\",\"#1\",\"#2\",\"#0\",\"#2\",\"#1\",\"#3\",\"#0\",\"#3\",\"#1\",\"#2\",\"#0\",\"#3\",\"#3\",\"#0\",\"#2\",\"#1\",\"#1\",\"#0\",\"#3\",\"#2\",\"#2\"],\"id\":[[7,3],[1,3],[9,1],[3,0],[8,0],[2,1],[6,2],[5,1],[10,3],[7,2],[4,0],[1,2],[9,0],[3,3],[8,1],[6,3],[5,0],[2,2],[10,0],[4,1],[1,1],[3,2],[0,0],[8,2],[7,1],[9,3],[6,0],[2,3],[10,1],[4,2],[1,0],[5,3],[8,3],[7,0],[9,2],[6,1],[3,1],[2,0],[4,3],[5,2],[10,2]],\"is_best\":[false,false,false,true,true,false,false,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,true,false,false,false,false,false,false,false,true,false,false,true,false,true,false,true,false,false,false],\"line_color\":[\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\"],\"line_width\":[1,1,1,3,3,1,1,3,1,1,1,1,3,1,1,1,1,1,1,3,1,1,3,1,1,1,1,1,1,1,3,1,1,3,1,3,1,3,1,1,1],\"parent_id\":[[6,0],[0,0],[8,0],[2,0],[7,0],[1,1],[5,0],[4,1],[9,1],[6,3],[3,0],[0,0],[8,0],[2,0],[7,1],[5,2],[4,0],[1,2],[9,1],[3,0],[0,0],[2,0],[0,0],[7,2],[6,0],[8,0],[5,0],[1,3],[9,1],[3,3],[0,0],[4,3],[7,0],[6,1],[8,2],[5,1],[2,0],[1,0],[3,0],[4,2],[9,1]],\"token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"token_font_size\":[\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\"],\"token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"token_text\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"x\":[7.0,1.0,9.0,3.0,8.0,2.0,6.0,5.0,10.0,7.0,4.0,1.0,9.0,3.0,8.0,6.0,5.0,2.0,10.0,4.0,1.0,3.0,0.0,8.0,7.0,9.0,6.0,2.0,10.0,4.0,1.0,5.0,8.0,7.0,9.0,6.0,3.0,2.0,4.0,5.0,10.0],\"y\":[4.333333333333333,-1.5,3.333333333333333,3.0,3.333333333333333,0.5,3.833333333333333,2.833333333333333,1.833333333333333,0.0,4.333333333333333,-0.5,4.333333333333333,0.0,5.333333333333333,0.0,4.333333333333333,-0.5,4.833333333333333,2.833333333333333,0.5,1.0,0.0,0.0,5.333333333333333,2.333333333333333,4.833333333333333,-1.5,3.833333333333333,0.0,1.5,1.8333333333333333,2.333333333333333,2.833333333333333,0.0,2.833333333333333,2.0,1.5,1.8333333333333333,0.0,2.833333333333333]}},\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":{\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"ca8bf926-99b6-41f8-aa58-31f717609a35\",\"type\":\"PanTool\"},{\"id\":\"0170b055-6020-406e-b0a6-9a42a9bb2816\",\"type\":\"BoxZoomTool\"},{\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},{\"id\":\"e4e04654-061b-4633-a71e-1c9003f6bda9\",\"type\":\"WheelZoomTool\"},{\"id\":\"7d459b4a-fdec-48b5-bc95-828fb94c3c34\",\"type\":\"SaveTool\"},{\"id\":\"cacbfd1a-7e88-471a-a3c1-bc588c6af09c\",\"type\":\"ResetTool\"},{\"id\":\"7a2caa64-375a-466a-8caf-c9f17555b42d\",\"type\":\"HoverTool\"}]},\"id\":\"58f26099-07c1-4f46-ba5f-eec6d745dd12\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"dd1456df-a3c2-4dcc-a8aa-769ac1a8a3b2\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"vertices\",\"nonselection_glyph\":{\"id\":\"43ae4eb3-d229-4335-a758-a5d18149bd65\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"2e9dcf01-3f79-4337-b7dd-26f0525180b9\",\"type\":\"CDSView\"}},\"id\":\"eb321d59-0d82-41f4-966f-a84597d90781\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"b0f21dbb-aa92-495c-9a38-9881564a3daa\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"a3e71058-805b-4461-9009-2e76107d0dad\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"eabb5e31-0740-4852-bcac-887155d4c0fc\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"ddf587aa-019f-43a1-af8c-52144e732785\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"decoding step (aka output length)\",\"formatter\":{\"id\":\"f3857a7d-2e4f-4ce0-b897-cec5490c8436\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"859d93b7-acac-4853-be74-6f20da679d8b\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"d4854422-d3bc-43fa-b7c0-a791e40b8a05\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"ca8bf926-99b6-41f8-aa58-31f717609a35\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"a931ac6d-24c6-489e-873f-3785a4f5cec4\",\"type\":\"CDSView\"},{\"attributes\":{\"bounds\":[-11.5,15.333333333333332],\"callback\":null,\"range_padding\":1.0,\"range_padding_units\":\"absolute\"},\"id\":\"b765029c-d346-49e8-b769-3c8155e12984\",\"type\":\"DataRange1d\"},{\"attributes\":{\"interval\":1},\"id\":\"859d93b7-acac-4853-be74-6f20da679d8b\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"323b0eea-1d7f-4a0d-84fe-74a9d6ac6b56\",\"type\":\"Text\"},{\"attributes\":{\"below\":[{\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"}],\"plot_width\":900,\"renderers\":[{\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"},{\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"},{\"id\":\"004b26cb-f235-4bd3-9464-2eed25a63945\",\"type\":\"Grid\"},{\"id\":\"0657e055-fa58-43fe-a3b8-b2b719174d8a\",\"type\":\"GlyphRenderer\"},{\"id\":\"eb321d59-0d82-41f4-966f-a84597d90781\",\"type\":\"GlyphRenderer\"},{\"id\":\"6ac35546-2a42-40c8-aa62-146d57d2f556\",\"type\":\"GlyphRenderer\"},{\"id\":\"5a71f9c4-4314-4eda-a1d8-25124c2b23d2\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"f04dd0c6-c641-4580-87f7-c0f878d1c0e6\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"3175d402-0679-462f-b9d4-d947ff7ad2b3\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"a5cebe80-c44b-4d0a-aae2-c2f3b9ef2475\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"d8a43b51-3e35-4c6f-bb08-c7be8e8c3ce2\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"b765029c-d346-49e8-b769-3c8155e12984\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"a0929048-0a2d-4f8f-8d58-e4a6d0106ad1\",\"type\":\"LinearScale\"}},\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d4854422-d3bc-43fa-b7c0-a791e40b8a05\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"tokens\",\"nonselection_glyph\":{\"id\":\"17a29716-8304-471c-9f48-6dd74ade100a\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"5d7f1257-5695-4ee0-8fe7-f29e498f83c7\",\"type\":\"CDSView\"}},\"id\":\"6ac35546-2a42-40c8-aa62-146d57d2f556\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"a10f3b4a-982e-4c44-b026-f8088199fe6f\",\"type\":\"Text\"},{\"attributes\":{\"plot\":{\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"21b07e0f-be09-4617-8f50-6b55adf59566\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"d3dfd7db-0295-4068-89b6-6a86f9141772\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"Beam search\"},\"id\":\"f04dd0c6-c641-4580-87f7-c0f878d1c0e6\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"323b0eea-1d7f-4a0d-84fe-74a9d6ac6b56\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"hypo_i\",\"nonselection_glyph\":{\"id\":\"a10f3b4a-982e-4c44-b026-f8088199fe6f\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"b0f21dbb-aa92-495c-9a38-9881564a3daa\",\"type\":\"CDSView\"}},\"id\":\"d6b0d875-955c-493f-8f95-7f155de46db0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"5d7f1257-5695-4ee0-8fe7-f29e498f83c7\",\"type\":\"CDSView\"},{\"attributes\":{\"overlay\":{\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"}},\"id\":\"0170b055-6020-406e-b0a6-9a42a9bb2816\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"bounds\":[-10.0,20.0],\"callback\":null,\"end\":12,\"js_property_callbacks\":{\"change:end\":[{\"id\":\"b56f32a3-d365-46b7-9f4f-323382959b2d\",\"type\":\"CustomJS\"}]},\"start\":-1},\"id\":\"a5cebe80-c44b-4d0a-aae2-c2f3b9ef2475\",\"type\":\"Range1d\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"09035c87-81aa-4e21-b586-281eec2ac195\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":{\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"cab35414-b6a5-47d8-a8cd-55b26f7a7b54\",\"type\":\"PanTool\"},{\"id\":\"64b6f55d-2417-4701-8845-e39dd839273e\",\"type\":\"BoxZoomTool\"},{\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},{\"id\":\"7a97466a-a0c3-4c9a-93bc-f7d1909c09da\",\"type\":\"WheelZoomTool\"},{\"id\":\"a8cad25e-8062-4326-b4df-8b1d1db279c7\",\"type\":\"SaveTool\"},{\"id\":\"237d0e16-242f-45d0-81da-35c5b34ecdb4\",\"type\":\"ResetTool\"},{\"id\":\"ce962e54-6eaa-4a63-b602-ab2387d43716\",\"type\":\"HoverTool\"}]},\"id\":\"3175d402-0679-462f-b9d4-d947ff7ad2b3\",\"type\":\"Toolbar\"},{\"attributes\":{\"dimensions\":\"height\"},\"id\":\"e4e04654-061b-4633-a71e-1c9003f6bda9\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"8c80ac74-34fc-4790-a100-c62b151ded39\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"a0929048-0a2d-4f8f-8d58-e4a6d0106ad1\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"7d459b4a-fdec-48b5-bc95-828fb94c3c34\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":{\"field\":\"hypo_i_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_baseline\":\"middle\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12px\"},\"text_font_style\":\"bold\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1aaad8cb-1c94-4061-b4ce-f70e91e33b07\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"d8a43b51-3e35-4c6f-bb08-c7be8e8c3ce2\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"cacbfd1a-7e88-471a-a3c1-bc588c6af09c\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"8c80ac74-34fc-4790-a100-c62b151ded39\",\"type\":\"Text\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"hypo_i\",\"nonselection_glyph\":{\"id\":\"1aaad8cb-1c94-4061-b4ce-f70e91e33b07\",\"type\":\"Text\"},\"selection_glyph\":null,\"view\":{\"id\":\"a931ac6d-24c6-489e-873f-3785a4f5cec4\",\"type\":\"CDSView\"}},\"id\":\"5a71f9c4-4314-4eda-a1d8-25124c2b23d2\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"names\":[\"vertices\"],\"tooltips\":[[\"token\",\"@_on_hover_token\"],[\"token_id\",\"@_on_hover_token_id\"],[\"score\",\"@_on_hover_score\"]]},\"id\":\"7a2caa64-375a-466a-8caf-c9f17555b42d\",\"type\":\"HoverTool\"},{\"attributes\":{\"interval\":1},\"id\":\"21b07e0f-be09-4617-8f50-6b55adf59566\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"decoding step (aka output length)\",\"formatter\":{\"id\":\"e26ba807-3a3a-43be-8db2-601d280799bd\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"c0496269-9e06-46af-ab94-5438bfbff629\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"13a5308f-70ad-452e-af22-43861fd0cb71\",\"type\":\"LinearAxis\"},{\"attributes\":{\"interval\":1},\"id\":\"c0496269-9e06-46af-ab94-5438bfbff629\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"args\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"code\":\"\\n            var x_range = cb_obj;\\n            var font_size = Math.round(14 * 13.0 / (x_range.end - x_range.start));\\n\\n            font_size = Math.min(24, Math.max(font_size, 0));\\n            \\n            var data = source.data;\\n            var fs = data['token_font_size']\\n            \\n            for (var i = 0; i < fs.length; i++)\\n                fs[i] = font_size.toString() + \\\"px\\\";\\n            \\n            source.change.emit();\\n        \"},\"id\":\"eab13fb4-9405-4d14-8bf6-46c6f698b4bb\",\"type\":\"CustomJS\"},{\"attributes\":{},\"id\":\"cab35414-b6a5-47d8-a8cd-55b26f7a7b54\",\"type\":\"PanTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d47ea423-d422-49a0-b24d-798a01f47236\",\"type\":\"Circle\"},{\"attributes\":{\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"d4677ed5-e7ac-4a9f-960d-0463a72b4947\",\"type\":\"MultiLine\"},{\"attributes\":{\"callback\":null,\"names\":[\"vertices\"],\"tooltips\":[[\"token\",\"@_on_hover_token\"],[\"token_id\",\"@_on_hover_token_id\"],[\"score\",\"@_on_hover_score\"]]},\"id\":\"ce962e54-6eaa-4a63-b602-ab2387d43716\",\"type\":\"HoverTool\"},{\"attributes\":{\"overlay\":{\"id\":\"59657239-6604-4439-8bf1-83a5ab659d4a\",\"type\":\"BoxAnnotation\"}},\"id\":\"64b6f55d-2417-4701-8845-e39dd839273e\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"72b704fc-ca92-4d86-89ae-f33aeb3c23a8\",\"type\":\"MultiLine\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"fbfb1ccf-b06f-43d0-93b8-b7a2feb2e51e\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"5574258e-e46b-409c-af99-02931bf42c33\",\"type\":\"MultiLine\"},{\"attributes\":{\"fill_color\":{\"field\":\"circle_fill_color\"},\"line_color\":{\"field\":\"line_color\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"dd1456df-a3c2-4dcc-a8aa-769ac1a8a3b2\",\"type\":\"Circle\"},{\"attributes\":{\"dimensions\":\"height\"},\"id\":\"7a97466a-a0c3-4c9a-93bc-f7d1909c09da\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"fill_color\":{\"field\":\"circle_fill_color\"},\"line_color\":{\"field\":\"line_color\"},\"line_width\":{\"field\":\"line_width\"},\"size\":{\"units\":\"screen\",\"value\":24},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"14c2f957-8e96-40e9-8d5a-bbe84ee0131a\",\"type\":\"Circle\"},{\"attributes\":{\"args\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"code\":\"\\n            var x_range = cb_obj;\\n            var font_size = Math.round(14 * 13.0 / (x_range.end - x_range.start));\\n\\n            font_size = Math.min(24, Math.max(font_size, 0));\\n            \\n            var data = source.data;\\n            var fs = data['token_font_size']\\n            \\n            for (var i = 0; i < fs.length; i++)\\n                fs[i] = font_size.toString() + \\\"px\\\";\\n            \\n            source.change.emit();\\n        \"},\"id\":\"b56f32a3-d365-46b7-9f4f-323382959b2d\",\"type\":\"CustomJS\"},{\"attributes\":{},\"id\":\"a8cad25e-8062-4326-b4df-8b1d1db279c7\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"237d0e16-242f-45d0-81da-35c5b34ecdb4\",\"type\":\"ResetTool\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"5574258e-e46b-409c-af99-02931bf42c33\",\"type\":\"MultiLine\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"edges\",\"nonselection_glyph\":{\"id\":\"72b704fc-ca92-4d86-89ae-f33aeb3c23a8\",\"type\":\"MultiLine\"},\"selection_glyph\":null,\"view\":{\"id\":\"95e7b794-7dda-4997-b7c6-a664964f6b5a\",\"type\":\"CDSView\"}},\"id\":\"978e683c-44ae-4bb3-b7d1-4660f2415803\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"interval\":1},\"id\":\"aaf5ec9a-6f51-45f4-a1b5-d2a8ac2cb5e0\",\"type\":\"SingleIntervalTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"14c2f957-8e96-40e9-8d5a-bbe84ee0131a\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"vertices\",\"nonselection_glyph\":{\"id\":\"d47ea423-d422-49a0-b24d-798a01f47236\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"dd940c41-87e6-4094-8be6-3dc7f22f0921\",\"type\":\"CDSView\"}},\"id\":\"cdf3b0e4-fe4f-450f-86d4-c51260c5d8c0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"aaf5ec9a-6f51-45f4-a1b5-d2a8ac2cb5e0\",\"type\":\"SingleIntervalTicker\"}},\"id\":\"004b26cb-f235-4bd3-9464-2eed25a63945\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"}},\"id\":\"b553c853-cc22-4ae3-aea6-95ad360ad0fc\",\"type\":\"CDSView\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"95e7b794-7dda-4997-b7c6-a664964f6b5a\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"id\",\"parent_id\",\"children_ids\",\"is_best\",\"depth\",\"hypo_i\",\"token\",\"token_id\",\"x\",\"y\",\"circle_fill_color\",\"line_color\",\"line_width\",\"edge_xx\",\"edge_yy\",\"token_text\",\"token_font_size\",\"hypo_i_text\",\"hypo_i_offset\",\"_on_hover_token\",\"_on_hover_token_id\",\"_on_hover_score\"],\"data\":{\"_on_hover_score\":[\"-4.7282\",\"-4.2071\",\"-4.8782\",\"-1.3577\",\"-4.0420\",\"-4.2097\",\"-4.5624\",\"-3.2410\",\"-6.9225\",\"-4.6717\",\"-2.8497\",\"-3.8023\",\"-4.1460\",\"-3.6443\",\"-4.3135\",\"-4.7070\",\"-3.1373\",\"-4.5105\",\"-6.1526\",\"-3.0974\",\"-3.7421\",\"-3.4956\",\"0.0000\",\"-5.2694\",\"-4.4104\",\"-6.1752\",\"-3.7617\",\"-4.6281\",\"-6.5626\",\"-3.7175\",\"-0.7384\",\"-4.5439\",\"-5.2967\",\"-3.6831\",\"-5.2153\",\"-3.7830\",\"-3.1335\",\"-0.8716\",\"-3.7312\",\"-3.8895\",\"-6.5984\"],\"_on_hover_token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"_on_hover_token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"children_ids\":[[],[[2,3]],[[10,3],[10,2],[10,1],[10,0]],[[4,3],[4,1],[4,0]],[[9,3],[9,1],[9,0]],[],[],[[6,1]],[],[[8,2]],[[5,0]],[[2,2]],[],[[4,2]],[],[[7,2]],[[6,2],[6,0]],[],[],[[5,1]],[[2,1]],[],[[1,3],[1,2],[1,1],[1,0]],[[9,2]],[[8,1]],[],[[7,3],[7,1]],[],[],[[5,2]],[[2,0]],[],[],[[8,3],[8,0]],[],[[7,0]],[],[[3,3],[3,2],[3,1],[3,0]],[[5,3]],[[6,3]],[]],\"circle_fill_color\":[\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\",\"#87CEEB\"],\"depth\":[7,1,9,3,8,2,6,5,10,7,4,1,9,3,8,6,5,2,10,4,1,3,0,8,7,9,6,2,10,4,1,5,8,7,9,6,3,2,4,5,10],\"edge_xx\":[[6.0,7.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[1.0,2.0],[5.0,6.0],[4.0,5.0],[9.0,10.0],[6.0,7.0],[3.0,4.0],[0.0,1.0],[8.0,9.0],[2.0,3.0],[7.0,8.0],[5.0,6.0],[4.0,5.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[2.0,3.0],[0.0,0.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[1.0,2.0],[9.0,10.0],[3.0,4.0],[0.0,1.0],[4.0,5.0],[7.0,8.0],[6.0,7.0],[8.0,9.0],[5.0,6.0],[2.0,3.0],[1.0,2.0],[3.0,4.0],[4.0,5.0],[9.0,10.0]],\"edge_yy\":[[4.833333333333333,4.333333333333333],[0.0,-1.5],[3.333333333333333,3.333333333333333],[1.5,3.0],[2.833333333333333,3.333333333333333],[0.5,0.5],[4.333333333333333,3.833333333333333],[2.833333333333333,2.833333333333333],[3.333333333333333,1.833333333333333],[0.0,0.0],[3.0,4.333333333333333],[0.0,-0.5],[3.333333333333333,4.333333333333333],[1.5,0.0],[5.333333333333333,5.333333333333333],[0.0,0.0],[4.333333333333333,4.333333333333333],[-0.5,-0.5],[3.333333333333333,4.833333333333333],[3.0,2.833333333333333],[0.0,0.5],[1.5,1.0],[0.0,0.0],[0.0,0.0],[4.833333333333333,5.333333333333333],[3.333333333333333,2.333333333333333],[4.333333333333333,4.833333333333333],[-1.5,-1.5],[3.333333333333333,3.833333333333333],[0.0,0.0],[0.0,1.5],[1.8333333333333333,1.8333333333333333],[2.833333333333333,2.333333333333333],[2.833333333333333,2.833333333333333],[0.0,0.0],[2.833333333333333,2.833333333333333],[1.5,2.0],[1.5,1.5],[3.0,1.8333333333333333],[0.0,0.0],[3.333333333333333,2.833333333333333]],\"hypo_i\":[3,3,1,0,0,1,2,1,3,2,0,2,0,3,1,3,0,2,0,1,1,2,0,2,1,3,0,3,1,2,0,3,3,0,2,1,1,0,3,2,2],\"hypo_i_offset\":[-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8,-8],\"hypo_i_text\":[\"#3\",\"#3\",\"#1\",\"#0\",\"#0\",\"#1\",\"#2\",\"#1\",\"#3\",\"#2\",\"#0\",\"#2\",\"#0\",\"#3\",\"#1\",\"#3\",\"#0\",\"#2\",\"#0\",\"#1\",\"#1\",\"#2\",\"#0\",\"#2\",\"#1\",\"#3\",\"#0\",\"#3\",\"#1\",\"#2\",\"#0\",\"#3\",\"#3\",\"#0\",\"#2\",\"#1\",\"#1\",\"#0\",\"#3\",\"#2\",\"#2\"],\"id\":[[7,3],[1,3],[9,1],[3,0],[8,0],[2,1],[6,2],[5,1],[10,3],[7,2],[4,0],[1,2],[9,0],[3,3],[8,1],[6,3],[5,0],[2,2],[10,0],[4,1],[1,1],[3,2],[0,0],[8,2],[7,1],[9,3],[6,0],[2,3],[10,1],[4,2],[1,0],[5,3],[8,3],[7,0],[9,2],[6,1],[3,1],[2,0],[4,3],[5,2],[10,2]],\"is_best\":[false,false,false,true,true,false,false,true,false,false,false,false,true,false,false,false,false,false,false,true,false,false,true,false,false,false,false,false,false,false,true,false,false,true,false,true,false,true,false,false,false],\"line_color\":[\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\"],\"line_width\":[1,1,1,3,3,1,1,3,1,1,1,1,3,1,1,1,1,1,1,3,1,1,3,1,1,1,1,1,1,1,3,1,1,3,1,3,1,3,1,1,1],\"parent_id\":[[6,0],[0,0],[8,0],[2,0],[7,0],[1,1],[5,0],[4,1],[9,1],[6,3],[3,0],[0,0],[8,0],[2,0],[7,1],[5,2],[4,0],[1,2],[9,1],[3,0],[0,0],[2,0],[0,0],[7,2],[6,0],[8,0],[5,0],[1,3],[9,1],[3,3],[0,0],[4,3],[7,0],[6,1],[8,2],[5,1],[2,0],[1,0],[3,0],[4,2],[9,1]],\"token\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"token_font_size\":[\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\",\"14px\"],\"token_id\":[1,780,25,2482,15356,2482,1879,3,17084,25,13862,5,1,7691,1,15356,25,15328,4255,11685,11,3487,-1,21342,15356,4,21342,11,1781,30,3622,3,25,1078,1,5093,26478,11,2451,13862,22624],\"token_text\":[\"_EOS_\",\"\\u043f\\u0440\\u0430\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0438\\u0432\\u0430\\u0435\\u0442\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0439\",\",\",\"\\u0443\\u043f\\u043b\\u0430\\u0442\\u044b\",\"\\u043e\\u0442\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u0432\",\"_EOS_\",\"\\u0432\\u044b\\u0441\\u0442\\u0443\\u043f\\u0430\\u0435\\u0442\",\"_EOS_\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\"\\u043e\\u0442\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\\u0435\",\"\\u043d\\u0430\\u043b\\u043e\\u0433\\u043e\\u0432\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043a\\u0438\",\"\\u043d\\u0435\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\",\"<empty>\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u0442\\u0438\\u043c\\u043e\\u0448\\u0435\\u043d\\u043a\\u043e\",\".\",\"\\u043f\\u043e\\u043f\\u0440\\u0430\\u0432\\u043e\\u043a\",\"\\u043d\\u0435\",\"\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0438\",\"\\u0437\\u0430\",\"\\u043f\\u0430\\u0440\\u043b\\u0430\\u043c\\u0435\\u043d\\u0442\",\",\",\"\\u043e\\u0442\",\"`\\u0430\\u044e\\u0449\\u0438\\u0435\",\"_EOS_\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\",\"\\u043f\\u043e\\u0434\\u0434\\u0435\\u0440\\u0436\\u0430\\u043b\",\"\\u043d\\u0435\",\"\\u0438\\u0437\\u043c\\u0435\\u043d\\u0435\\u043d\\u0438\\u0435\",\"\\u043e\\u0441\\u0432\\u043e\\u0431\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043f\\u0440\\u0435\\u0442\\u0435\\u043d\\u0437\\u0438\\u0439\"],\"x\":[7.0,1.0,9.0,3.0,8.0,2.0,6.0,5.0,10.0,7.0,4.0,1.0,9.0,3.0,8.0,6.0,5.0,2.0,10.0,4.0,1.0,3.0,0.0,8.0,7.0,9.0,6.0,2.0,10.0,4.0,1.0,5.0,8.0,7.0,9.0,6.0,3.0,2.0,4.0,5.0,10.0],\"y\":[4.333333333333333,-1.5,3.333333333333333,3.0,3.333333333333333,0.5,3.833333333333333,2.833333333333333,1.833333333333333,0.0,4.333333333333333,-0.5,4.333333333333333,0.0,5.333333333333333,0.0,4.333333333333333,-0.5,4.833333333333333,2.833333333333333,0.5,1.0,0.0,0.0,5.333333333333333,2.333333333333333,4.833333333333333,-1.5,3.833333333333333,0.0,1.5,1.8333333333333333,2.333333333333333,2.833333333333333,0.0,2.833333333333333,2.0,1.5,1.8333333333333333,0.0,2.833333333333333]}},\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"e26ba807-3a3a-43be-8db2-601d280799bd\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"field\":\"line_width\"},\"xs\":{\"field\":\"edge_xx\"},\"ys\":{\"field\":\"edge_yy\"}},\"id\":\"d41b7979-8903-4ee5-a861-1bf88bfb14ea\",\"type\":\"MultiLine\"},{\"attributes\":{\"source\":{\"id\":\"49a8987d-d307-4797-9fae-8ec771f76b48\",\"type\":\"ColumnDataSource\"}},\"id\":\"dd940c41-87e6-4094-8be6-3dc7f22f0921\",\"type\":\"CDSView\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"17a29716-8304-471c-9f48-6dd74ade100a\",\"type\":\"Text\"},{\"attributes\":{},\"id\":\"f3857a7d-2e4f-4ce0-b897-cec5490c8436\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"53346d3c-7b75-4689-95d1-c395b23fa5b8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d4677ed5-e7ac-4a9f-960d-0463a72b4947\",\"type\":\"MultiLine\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"edges\",\"nonselection_glyph\":{\"id\":\"d41b7979-8903-4ee5-a861-1bf88bfb14ea\",\"type\":\"MultiLine\"},\"selection_glyph\":null,\"view\":{\"id\":\"b553c853-cc22-4ae3-aea6-95ad360ad0fc\",\"type\":\"CDSView\"}},\"id\":\"0657e055-fa58-43fe-a3b8-b2b719174d8a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_alpha\":{\"value\":0.1},\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"3621fd59-3cb3-4305-8802-6f7f75a23fd6\",\"type\":\"Text\"},{\"attributes\":{\"bounds\":[-11.5,15.333333333333332],\"callback\":null,\"range_padding\":1.0,\"range_padding_units\":\"absolute\"},\"id\":\"3868f6e3-8193-418f-af89-ee5749e490a1\",\"type\":\"DataRange1d\"},{\"attributes\":{\"text\":{\"field\":\"token_text\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"field\":\"token_font_size\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"},\"y_offset\":{\"value\":-10}},\"id\":\"08bbcb52-00b5-4803-9e7a-9252db09708d\",\"type\":\"Text\"},{\"attributes\":{\"below\":[{\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"}],\"plot_width\":900,\"renderers\":[{\"id\":\"8033ebc0-a196-49a8-acdc-dbc0ae3fcf54\",\"type\":\"BoxAnnotation\"},{\"id\":\"84db9569-9f28-4a47-82c8-bfa01402aeb6\",\"type\":\"LinearAxis\"},{\"id\":\"d3dfd7db-0295-4068-89b6-6a86f9141772\",\"type\":\"Grid\"},{\"id\":\"978e683c-44ae-4bb3-b7d1-4660f2415803\",\"type\":\"GlyphRenderer\"},{\"id\":\"cdf3b0e4-fe4f-450f-86d4-c51260c5d8c0\",\"type\":\"GlyphRenderer\"},{\"id\":\"a2ab1853-0966-4519-874f-956f801f1c72\",\"type\":\"GlyphRenderer\"},{\"id\":\"d6b0d875-955c-493f-8f95-7f155de46db0\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"5af81591-5793-4721-a459-e0a4ca700855\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"58f26099-07c1-4f46-ba5f-eec6d745dd12\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"14e9976c-9458-4bce-be96-da2f3c304cec\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"eabb5e31-0740-4852-bcac-887155d4c0fc\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"3868f6e3-8193-418f-af89-ee5749e490a1\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"a3e71058-805b-4461-9009-2e76107d0dad\",\"type\":\"LinearScale\"}},\"id\":\"327205fd-12df-449f-9614-e6816136cb23\",\"subtype\":\"Figure\",\"type\":\"Plot\"}],\"root_ids\":[\"327205fd-12df-449f-9614-e6816136cb23\",\"91387928-8f01-4237-9a5d-24f1d6f93c23\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.7\"}};\n",
              "              var render_items = [{\"docid\":\"ba84f797-d201-498d-a731-5adafa5447b7\",\"elementid\":\"ff8c3f31-952d-4c2f-8b58-13e7cec51b58\",\"modelid\":\"91387928-8f01-4237-9a5d-24f1d6f93c23\"}];\n",
              "              \n",
              "              Bokeh.embed.embed_items(docs_json, render_items);\n",
              "            });\n",
              "          };\n",
              "          if (document.readyState != \"loading\") fn();\n",
              "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "        })();\n",
              "        \n",
              "        </script>\n",
              "    </body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkZjVusArtYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search_decode(model, source_text, source_field, target_field, beam_size=5):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden = model.encoder(...source_text...)\n",
        "        beams = [([bos_index], 0, encoder_hidden)]\n",
        "        \n",
        "        # 1. make next step from each beam\n",
        "        # 2. create new beams from top beam_size of each continuation (best next token variants for the given token)\n",
        "        # 3. leave only top beam_size beams\n",
        "        # 4. repeat\n",
        "            \n",
        "        return ' '.join(target_field.vocab.itos[ind.squeeze().item()] for ind in result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK4OdgTRQmqp",
        "colab_type": "text"
      },
      "source": [
        "## Улучшения модели\n",
        "\n",
        "**Задание** Попробуйте повысить качество модели. Попробуйте: \n",
        "- Bidirectional encoder\n",
        "- Dropout\n",
        "- Stack moar layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37gHrfjwywIK",
        "colab_type": "text"
      },
      "source": [
        "## Byte-Pair Encoding\n",
        "\n",
        "Мы можем представлять слова одним индексом - и использовать словные эмбеддинги как строки матрицы эмбеддингов.  \n",
        "Можем считать их набором символов и получать словный эмбеддинг с помощью некоторой функции над символьными эмбеддингами.\n",
        "\n",
        "Наконец, можем ещё использовать промежуточное представление - как набор подслов.\n",
        "\n",
        "Несколько лет назад использование подслов предложили для задачи машинного перевода: [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909). Там использовалось byte-pair encoding.\n",
        "\n",
        "По сути это процесс объединения самых частотных пар символов алфавита в новый суперсимвол. Пусть у нас есть словарь, состоящий из такого набора слов:  \n",
        "`‘low·’, ‘lowest·’, ‘newer·’, ‘wider·’`   \n",
        "(`·` означает конец слова)\n",
        "\n",
        "Тогда первым может выучиться новый символ `r·`, за ним `l o` превратится в `lo`. К этому новому символу приклеится `w`: `lo w` $\\to$ `low`. И так далее.\n",
        "\n",
        "Утверждается, что таким образом выучатся, во-первых, все частотные и короткие слова, а во-вторых, все значимые подслова. Например, в полученном в результате алфавите должны найтись `ly·` и `tion·`.\n",
        "\n",
        "Дальше слово можно разбить на набор подслов - и действовать, как с символами.\n",
        "\n",
        "Здесь можно найти уже предобученные эмбеддинги: [BPEmb](https://github.com/bheinzerling/bpemb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A9WFdh92zHr",
        "colab_type": "text"
      },
      "source": [
        "Обучим модель для них:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYsZoEu7zXY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from subword_nmt.learn_bpe import learn_bpe\n",
        "from subword_nmt.apply_bpe import BPE\n",
        "\n",
        "with open('data.en', 'w') as f_src, open('data.ru', 'w') as f_dst:\n",
        "    for example in examples:\n",
        "        f_src.write(' '.join(example.source) + '\\n')\n",
        "        f_dst.write(' '.join(example.target) + '\\n')\n",
        "\n",
        "bpe = {}\n",
        "for lang in ['en', 'ru']:\n",
        "    with open('./data.' + lang) as f_data, open('bpe_rules.' + lang, 'w') as f_rules:\n",
        "        learn_bpe(f_data, f_rules, num_symbols=3000)\n",
        "    with open('bpe_rules.' + lang) as f_rules:\n",
        "        bpe[lang] = BPE(f_rules)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWYVhaGx2vPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bpe['en'].process_line(' '.join(examples[10000].source))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g_s4vOO1_yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bpe['ru'].process_line(' '.join(examples[10000].target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf5MeBFw22wk",
        "colab_type": "text"
      },
      "source": [
        "**Задание** Переобучиться с subword'ами вместо слов. Возможно, поменять их число (`num_symbols`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcAdcldjB0y8",
        "colab_type": "text"
      },
      "source": [
        "# Image Captioning\n",
        "\n",
        "Не обязательно энкодить последовательности слов. Наример, можно использовать сверточную сеть для энкодера картинки - и генерировать подпись к ней:\n",
        "\n",
        "![](https://image.ibb.co/fpYdkL/image-captioning.png)  \n",
        "*From [Image Captioning Tutorial](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)*\n",
        "\n",
        "В результате получаются очень прикольные подписи: [https://cs.stanford.edu/people/karpathy/deepimagesent/](https://cs.stanford.edu/people/karpathy/deepimagesent/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIFL7T5FBXb8",
        "colab_type": "text"
      },
      "source": [
        "Скачаем данные для обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQJhK7XhBaPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '13BP-6Xd6ymhGallRppYfJBO6UUjFCtbB'})\n",
        "downloaded.GetContentFile('image_codes.npy')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1O7_3lyTyBMXsBBIt1PwUXwLdkyRQzZML'})\n",
        "downloaded.GetContentFile('sources.txt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1t-Dy8TzoRuTMoM7N9NJZKgWXfaw3b6KF'})\n",
        "downloaded.GetContentFile('texts.txt')\n",
        "\n",
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_Dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IQ--RKqDK2Q",
        "colab_type": "text"
      },
      "source": [
        "Скачем предобученную модельку:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrHFVqVYCn09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.inception import Inception3\n",
        "\n",
        "class BeheadedInception3(Inception3):\n",
        "    \"\"\" Like torchvision.models.inception.Inception3 but the head goes separately \"\"\"\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.clone()\n",
        "        x[:, 0] = x[:, 0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "        x[:, 1] = x[:, 1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "        x[:, 2] = x[:, 2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "        x = self.Conv2d_1a_3x3(x)\n",
        "        x = self.Conv2d_2a_3x3(x)\n",
        "        x = self.Conv2d_2b_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Conv2d_3b_1x1(x)\n",
        "        x = self.Conv2d_4a_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Mixed_5b(x)\n",
        "        x = self.Mixed_5c(x)\n",
        "        x = self.Mixed_5d(x)\n",
        "        x = self.Mixed_6a(x)\n",
        "        x = self.Mixed_6b(x)\n",
        "        x = self.Mixed_6c(x)\n",
        "        x = self.Mixed_6d(x)\n",
        "        x = self.Mixed_6e(x)\n",
        "        x = self.Mixed_7a(x)\n",
        "        x = self.Mixed_7b(x)\n",
        "        x_for_attn = x = self.Mixed_7c(x)\n",
        "        # 8 x 8 x 2048\n",
        "        x = F.avg_pool2d(x, kernel_size=8)\n",
        "        # 1 x 1 x 2048\n",
        "        x_for_capt = x = x.view(x.size(0), -1)\n",
        "        # 2048\n",
        "        x = self.fc(x)\n",
        "        # 1000 (num_classes)\n",
        "        return x_for_attn, x_for_capt, x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuFp0zETCoZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.model_zoo import load_url\n",
        "\n",
        "inception_model = BeheadedInception3()\n",
        "\n",
        "inception_url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
        "inception_model.load_state_dict(load_url(inception_url))\n",
        "\n",
        "inception_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHc-aSErDN81",
        "colab_type": "text"
      },
      "source": [
        "Почему это вообще работает? Запустим модельку на картинке:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHAuLf2DCqrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.misc import imresize\n",
        "%matplotlib inline\n",
        "    \n",
        "img = plt.imread('Flicker8k_Dataset/1000268201_693b08cb0e.jpg')\n",
        "img = imresize(img, (299, 299)).astype('float32') / 255.\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERVd_yomCtrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "LABELS_URL = 'https://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
        "labels = {int(key): value for (key, value) in requests.get(LABELS_URL).json().items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    img_tensor = torch.tensor(img.transpose([2, 0, 1]), dtype=torch.float32).unsqueeze(0)\n",
        "    _, _, logits = inception_model(img_tensor)\n",
        "    _, top_classes = logits.topk(5)\n",
        "\n",
        "    print('; '.join(labels[ind.item()] for ind in top_classes.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO_GWOkbDTqF",
        "colab_type": "text"
      },
      "source": [
        "Она выдает такие классы.\n",
        "\n",
        "Подписи же к картинке такие:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9fgGaG7CvQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('texts.txt') as f:\n",
        "    text = f.readline().strip().split('\\t')\n",
        "print('\\n'.join(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU4A4rjRDZX8",
        "colab_type": "text"
      },
      "source": [
        "Загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Sl4VFHCw18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_field = Field(sequential=False, use_vocab=False, dtype=torch.float)\n",
        "target_field = Field(init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "path_field = Field(sequential=False, use_vocab=True)\n",
        "\n",
        "fields = [('source', source_field), ('target', target_field), ('path', path_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXv4MEO0C33z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_vectors = np.load('image_codes.npy')\n",
        "\n",
        "examples = []\n",
        "with open('texts.txt') as f_texts, open('sources.txt') as f_sources:\n",
        "    for img, texts, source in zip(img_vectors, f_texts, f_sources):\n",
        "        for text in texts.split('\\t'):\n",
        "            examples.append(Example.fromlist([img, target_field.preprocess(text), source.rstrip()], fields))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8imy6UUC5mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=2)\n",
        "path_field.build_vocab(dataset)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 512), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngs3fUFyDbZ4",
        "colab_type": "text"
      },
      "source": [
        "**Задание** Реализуйте декодер для модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRNmlDAPC7YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, cnn_feature_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._cnn_to_h0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._cnn_to_c0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._rnn = nn.LSTM(input_size=emb_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_output, inputs, hidden=None):\n",
        "        ...\n",
        "    \n",
        "    def init_hidden(self, encoder_output):\n",
        "        encoder_output = encoder_output.unsqueeze(0)\n",
        "        return self._cnn_to_h0(encoder_output), self._cnn_to_c0(encoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhdX4BcqDmLa",
        "colab_type": "text"
      },
      "source": [
        "Хак, чтобы все работало со старым циклом обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwl46PpCC_xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model, iterator):\n",
        "    return 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC2s10FqC92K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Decoder(vocab_size=len(target_field.vocab), cnn_feature_size=img_vectors.shape[1]).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4rA1O3JDqt-",
        "colab_type": "text"
      },
      "source": [
        "Проверим, что работает генерация:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2daTHESDGjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(test_iter))\n",
        "\n",
        "img = path_field.vocab.itos[batch.path[0].item()]\n",
        "\n",
        "img = plt.imread('Flicker8k_Dataset/' + img)\n",
        "img = imresize(img, (299, 299)).astype('float32') / 255.\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G5jlZGCDwSW",
        "colab_type": "text"
      },
      "source": [
        "**Задание** Напишите цикл генерации из модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2cTrWGPDI0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N4-3pYqVJIKA"
      },
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Статьи\n",
        "Sequence to Sequence Learning with Neural Networks, Ilya Sutskever, et al, 2014 [[pdf]](https://arxiv.org/pdf/1409.3215.pdf)  \n",
        "Show and Tell: A Neural Image Caption Generator, Oriol Vinyals et al, 2014 [[arxiv]](https://arxiv.org/abs/1411.4555)  \n",
        "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks, Samy Bengio, et al, 2015 [[arxiv]](https://arxiv.org/abs/1506.03099)  \n",
        "Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich, 2015 [[arxiv]](https://arxiv.org/abs/1508.07909)  \n",
        "Massive Exploration of Neural Machine Translation Architectures, Denny Britz, et al, 2017 [[pdf]](https://arxiv.org/pdf/1703.03906.pdf)\n",
        "\n",
        "## Блоги\n",
        "Neural Machine Translation (seq2seq) Tutorial [tensorflow/nmt](https://github.com/tensorflow/nmt)  \n",
        "[A Word of Caution on Scheduled Sampling for Training RNNs](https://www.inference.vc/scheduled-sampling-for-rnns-scoring-rule-interpretation/)\n",
        "\n",
        "## Видео\n",
        "cs224n, [Machine Translation, Seq2Seq and Attention](https://www.youtube.com/watch?v=IxQtK2SjWWM)\n",
        "\n",
        "## Разное\n",
        "[The Annotated Encoder Decoder](https://bastings.github.io/annotated_encoder_decoder/)  \n",
        "[Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models](http://seq2seq-vis.io)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwb5e5hPQebd",
        "colab_type": "text"
      },
      "source": [
        "# Сдача\n",
        "\n",
        "[Форма для сдачи](https://goo.gl/forms/28RaQihilt5NChaI2)  \n",
        "[Feedback](https://goo.gl/forms/9aizSzOUrx7EvGlG3)"
      ]
    }
  ]
}