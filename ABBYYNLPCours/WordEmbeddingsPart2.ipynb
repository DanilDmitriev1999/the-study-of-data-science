{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbeddingsPart2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vacV4BIFI8l",
        "colab_type": "code",
        "outputId": "37ff0cad-90b0-4bac-c278-5fd6f88aa434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip install -q --upgrade nltk gensim bokeh pandas\n",
        "\n",
        "!wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
        "!unzip quora.zip\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  quora.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFSTdJG95SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpWIAreB6ky",
        "colab_type": "text"
      },
      "source": [
        "# Введение в PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M0mMOadG8aZ",
        "colab_type": "text"
      },
      "source": [
        "PyTorch - это один из самых известных фреймворков для работы с нейронными сетями.\n",
        "\n",
        "Почему именно он? Ну, он няшен, питоняч и проще в отладке - по сравнению с монстрами типа tensoflow (хотя tf 2.0 с eager execution будет примерно таким же).\n",
        "\n",
        "И вообще, мы тут не фреймворки, а сеточки учить собирались :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsScdJ7DLZCm",
        "colab_type": "text"
      },
      "source": [
        "## Автоматическое дифференцирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY9FHLM-M4aW",
        "colab_type": "text"
      },
      "source": [
        "### Графы вычислений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkvCloDpNXdH",
        "colab_type": "text"
      },
      "source": [
        "Графы вычислений - это такой удобный способ быстро считать градиенты сложных-пресложных функций.\n",
        "\n",
        "Например, функция\n",
        "\n",
        "$$f = (x + y) \\cdot z$$\n",
        "\n",
        "представится графом\n",
        "\n",
        "![graph](https://image.ibb.co/mWM0Lx/1_6o_Utr7_ENFHOK7_J4l_XJtw1g.png)  \n",
        "*From [Backpropagation, Intuitions - CS231n](http://cs231n.github.io/optimization-2/)*\n",
        "\n",
        "**Задание** Зададим значения $x, y, z$ (зеленым на картинке). Как посчитать $\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}$? (*Вспоминаем, что такое backpropagation*)\n",
        "\n",
        "В PyTorch такие вычисления делаются очень просто.\n",
        "\n",
        "Сначала определяется функция - просто последовательность операций:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4ASRktLdO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(-2., requires_grad=True)\n",
        "y = torch.tensor(5., requires_grad=True)\n",
        "z = torch.tensor(-4., requires_grad=True)\n",
        "\n",
        "q = x + y\n",
        "f = q * z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78COM99N8YL",
        "colab_type": "text"
      },
      "source": [
        "А затем говорим ей: \"Посчитай градиенты, пожалуйста\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FOlPMIQMfbq",
        "colab_type": "code",
        "outputId": "0797f81d-0445-4697-9324-7e40fb71b8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "f.backward()\n",
        "\n",
        "print('df/dz =', z.grad)\n",
        "print('df/dx =', x.grad)\n",
        "print('df/dy =', y.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df/dz = tensor(3.)\n",
            "df/dx = tensor(-4.)\n",
            "df/dy = tensor(-4.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JotDf1naGU-R",
        "colab_type": "text"
      },
      "source": [
        "Вызов метода `backward()` вычисляет градиенты для всех тензоров, у которых `requires_grad == True`.\n",
        "\n",
        "Есть еще альтернативный способ не вычислять градиенты - пользоваться менеджерами контекста ([Locally disabling gradient computation](https://pytorch.org/docs/stable/autograd.html#locally-disabling-gradient-computation)):\n",
        "```python\n",
        "torch.autograd.no_grad()\n",
        "torch.autograd.enable_grad()\n",
        "torch.autograd.set_grad_enabled(mode)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQEJeqfnJPpA",
        "colab_type": "code",
        "outputId": "aa407edd-2a2e-421e-93e9-376d25932d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "with torch.autograd.no_grad():\n",
        "    x = torch.tensor(-2., requires_grad=True)\n",
        "    y = torch.tensor(5., requires_grad=True)\n",
        "    q = x + y\n",
        "\n",
        "z = torch.tensor(-4., requires_grad=True)\n",
        "f = q * z\n",
        "\n",
        "f.backward()\n",
        "\n",
        "print('df/dz =', z.grad)\n",
        "print('df/dx =', x.grad)\n",
        "print('df/dy =', y.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df/dz = tensor(3.)\n",
            "df/dx = None\n",
            "df/dy = None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSiB1CGyJMzt",
        "colab_type": "text"
      },
      "source": [
        "Подробнее о том, как работает autograd, можно почитать здесь: [Autograd mechanics](https://pytorch.org/docs/stable/notes/autograd.html).\n",
        "\n",
        "В целом, любой тензор в pytorch - аналог многомерных матриц в numpy.\n",
        "\n",
        "Он содержит данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY2CcCw2Gmgq",
        "colab_type": "code",
        "outputId": "673737ab-a091-4206-f2c2-dce4b3dd8f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYxD8N_9GpJl",
        "colab_type": "text"
      },
      "source": [
        "Накопленный градиент:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYCD5P24GufX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwLx4szvGwMb",
        "colab_type": "text"
      },
      "source": [
        "Функцию, как градиент считать:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTfGdUF_GzV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q.grad_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgK1Esa6HHAB",
        "colab_type": "text"
      },
      "source": [
        "И всякую дополнительную метаинформацию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nazaer0AG4pL",
        "colab_type": "code",
        "outputId": "030c7207-0c44-4969-ab8a-787e039526d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x.type(), x.shape, x.device, x.layout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('torch.FloatTensor', torch.Size([]), device(type='cpu'), torch.strided)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvLFlc4iQOQv",
        "colab_type": "text"
      },
      "source": [
        "Зачем... У меня один вопрос - зачем вот это вот нам нужно?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlhLBWwHG3Xe",
        "colab_type": "text"
      },
      "source": [
        "### Задача для разминки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaqtIIvJOEut",
        "colab_type": "text"
      },
      "source": [
        "Чтобы разобраться - решим простенькую задачу на линейную регрессию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDZpEHF8AKH2",
        "colab_type": "code",
        "outputId": "00fb80f5-9815-47f4-c074-7c294782aa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "w_orig, b_orig = 2.6, -0.4\n",
        "\n",
        "X = np.random.rand(100) * 10. - 5.\n",
        "y_orig = w_orig * X + b_orig\n",
        "\n",
        "y = y_orig + np.random.randn(100)\n",
        "\n",
        "plt.plot(X, y, '.')\n",
        "plt.plot(X, y_orig)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZgp9/OICAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2K5MVtiSGuC",
        "colab_type": "text"
      },
      "source": [
        "Хочется прикрутить сюда backpropagation, да.\n",
        "\n",
        "Есть два параметра $w$ и $b$ - их нужно подобрать такими, чтобы они были как можно ближе к исходным $w_{orig}, b_{orig}$.\n",
        "\n",
        "Что будем оптимизировать? Оптимизировать будем MSE:\n",
        "$$J(w, b) = \\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - y_i(w, b)||^2 =\\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - (w \\cdot x_i + b)||^2. $$\n",
        "\n",
        "С такой функций потерь можем запустить простой градиентный спуск (даже не стохастический пока):\n",
        "$$w_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial w}(w_t, b_t)$$\n",
        "$$b_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial b}(w_t, b_t)$$\n",
        "\n",
        "**Задание** Реализовать оптимизацию на чистом numpy.\n",
        "\n",
        "Для этого нужно:\n",
        "1. Посчитать значение функции на прямом проходе: $y(w, b) = w \\cdot x + b$;\n",
        "2. Подумать и посчитать градиенты $\\frac{\\partial J}{\\partial w}, \\frac{\\partial J}{\\partial b}$ на обратном проходе;\n",
        "3. Сдвинуть $w, b$ по антиградиентам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKbqTNVXFB3A",
        "colab_type": "code",
        "outputId": "b477dbb9-912f-4d9b-914f-6e6f83b0f637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "def display_progress(epoch, loss, w, b, X, y, y_pred):\n",
        "    clear_output(True)\n",
        "    print('Epoch = {}, Loss = {}, w = {}, b = {}'.format(epoch, loss, w, b))\n",
        "    plt.plot(X, y, '.')\n",
        "    plt.plot(X, y_pred)\n",
        "    plt.show()\n",
        "    time.sleep(1)\n",
        "\n",
        "\n",
        "w = np.random.randn()\n",
        "b = np.random.randn()\n",
        "\n",
        "\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "for i in range(100):\n",
        "    y_pred = w * X + b\n",
        "\n",
        "    loss = ((y-y_pred)**2).sum()/len(y_pred)\n",
        "\n",
        "    w_grad = -2 / (y.shape[0]) * np.sum(X * (y - y_pred))\n",
        "    b_grad = -2 / (y.shape[0]) * np.sum(y - y_pred)\n",
        "\n",
        "    w -= alpha * w_grad\n",
        "    b -= alpha * b_grad\n",
        "    \n",
        "    if (i + 1) % 5 == 0:\n",
        "        display_progress(i + 1, loss, w, b, X, y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 100, Loss = 0.7178397998887753, w = 2.5834364451199177, b = -0.031443890427106276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8WgWrF4C2WK",
        "colab_type": "text"
      },
      "source": [
        "На PyTorch то же самое сделать несколько проще - подсчет прямого прохода копируется почти дословно.\n",
        "\n",
        "Обратный проход мы уже умеем - нужно просто вызвать `loss.backward()`.\n",
        "\n",
        "Для обновления `w` и `b` нужно иметь в виду следующее. Во-первых, pytorch не даст просто так обновить их:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4DoGeBMJd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = torch.randn(1, requires_grad=True)\n",
        "\n",
        "w -= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OjoUh-SMPBt",
        "colab_type": "text"
      },
      "source": [
        "Проблема в сложности поддержки in-place операций для работы autograd ([In place operations with autograd](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd)).\n",
        "\n",
        "Но нам и не нужна поддержка градиентов! Мы не будем делать backward pass через эту операцию - нужно всего лишь обновить значение переменной. Чтобы сделать это, можно воспользовать контекстом `no_grad`, либо производить обновление непосредственно буфера, который использует данный тензор:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zegkKd-cMOMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w.data -= 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVlaIdvHNXR_",
        "colab_type": "text"
      },
      "source": [
        "Другое, что нужно помнить - градиенты в тензорах накапливаются. Между вызовами `loss.backward()` нужно обнулять градиенты у `w` и `b`:\n",
        "```python\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "```\n",
        "\n",
        "**Задание** Реализовать линейную регрессию на pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRqxypuEU2ig",
        "colab_type": "code",
        "outputId": "8562a614-56fb-462d-9f9b-693ee30f3b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "X = torch.as_tensor(X).float()\n",
        "y = torch.as_tensor(y).float()\n",
        "\n",
        "w = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "alpha = 0.1\n",
        "\n",
        "for i in range(100):\n",
        "    y_pred = w * X + b\n",
        "\n",
        "    loss = ((y-y_pred)**2).sum()/len(y_pred)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    w.data -= alpha * w.grad\n",
        "    b.data -= alpha * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    \n",
        "    if (i + 1) % 5 == 0:\n",
        "        display_progress(i + 1, loss, w.item(), b.item(), \n",
        "                         X.data.numpy(), y.data.numpy(), y_pred.data.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 100, Loss = 0.6325293183326721, w = 2.5778634548187256, b = -0.3179955780506134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkQhTyIuIRNj/B15wiRJqQPd+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaKTKN_fOvo-",
        "colab_type": "text"
      },
      "source": [
        "Думать нужно уже гораздо меньше, да? :)\n",
        "\n",
        "Про другие фишки низкоуровнего pytorch можно почитать здесь: [PyTorch — ваш новый фреймворк глубокого обучения](https://habr.com/post/334380/) (статья веселая, но немного устарела, читать лучше с оглядкой на [PyTorch 0.4.0 Migration Guide](https://pytorch.org/blog/pytorch-0_4_0-migration-guide/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZNq6ujzPtvd",
        "colab_type": "text"
      },
      "source": [
        "## Word embeddings и высокоуровневый API PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITLgcVz66AfV",
        "colab_type": "text"
      },
      "source": [
        "Займёмся рассмотрением высокоуровневого API - в нем уже реализованы разные классы-запчасти для обучения нейронок.\n",
        "\n",
        "Будем решать всё ту же задачу, что и в прошлый раз - обучение словных эмбеддингов, только теперь мы будем учить их самостоятельно!\n",
        "\n",
        "Для начала нужно подготовить данные для обучения.\n",
        "\n",
        "Соберем и токенизируем тексты:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKKb9Ya8hzIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "quora_data = pd.read_csv('train.csv')\n",
        "\n",
        "quora_data.question1 = quora_data.question1.replace(np.nan, '', regex=True)\n",
        "quora_data.question2 = quora_data.question2.replace(np.nan, '', regex=True)\n",
        "\n",
        "texts = list(pd.concat([quora_data.question1, quora_data.question2]).unique())\n",
        "\n",
        "tokenized_texts = [word_tokenize(text.lower()) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYoj91iDDDfT",
        "colab_type": "text"
      },
      "source": [
        "Соберем индекс самых частотных слов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PL471pGjuVN",
        "colab_type": "code",
        "outputId": "c46a4d2c-f8d0-4418-e31f-5e3e198f10c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "MIN_COUNT = 5\n",
        "\n",
        "words_counter = Counter(token for tokens in tokenized_texts for token in tokens)\n",
        "word2index = {\n",
        "    '<unk>': 0\n",
        "}\n",
        "\n",
        "for word, count in words_counter.most_common():\n",
        "    if count < MIN_COUNT:\n",
        "        break\n",
        "        \n",
        "    word2index[word] = len(word2index)\n",
        "    \n",
        "index2word = [word for word, _ in sorted(word2index.items(), key=lambda x: x[1])]\n",
        "    \n",
        "print('Vocabulary size:', len(word2index))\n",
        "print('Tokens count:', sum(len(tokens) for tokens in tokenized_texts))\n",
        "print('Unknown tokens appeared:', sum(1 for tokens in tokenized_texts for token in tokens if token not in word2index))\n",
        "print('Most freq words:', index2word[1:21])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 28634\n",
            "Tokens count: 6969946\n",
            "Unknown tokens appeared: 123601\n",
            "Most freq words: ['?', 'the', 'what', 'is', 'a', 'i', 'to', 'in', 'how', 'of', 'do', 'are', 'and', 'for', ',', 'can', 'you', 'why', 'it', 'my']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF5mYpCsE9Uh",
        "colab_type": "text"
      },
      "source": [
        "### Skip-Gram Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1IG5XEMGRa",
        "colab_type": "text"
      },
      "source": [
        "Начнем с skip-gram модели обучения word2vec.\n",
        "\n",
        "Это простая модель всего из двух слоев. Ее идея - учить вектора эмбеддингов такими, чтобы по ним можно было как можно лучше предсказать контекст соответствующих слов. То есть если мы хорошо научились кодировать слова, с которыми встречается данное - значит, мы что-то знаем и о нем самом. Например, естественным образом получится, что слова, встречающиеся в одинаковых контекстах (скажем, `apple` и `orange`)  будут иметь близкие вектора эмбеддингов.\n",
        "\n",
        "![](https://ask.qcloudimg.com/http-save/yehe-1565119/pv4604cabp.jpeg)  \n",
        "*From cs224n, Lecture 2*\n",
        "\n",
        "Для этого мы моделируем вероятности $\\{P(w_{c+j}|w_c):  j = c-k, ..., c+k, j \\neq c\\}$, где $k$ - размер контекстного окна, $c$ - индекс центрального слова.\n",
        "\n",
        "Соберем такую модель: будем учить пару матриц $U$ - матрицу эмбеддингов, которую потом и возьмем для своих задач, и $V$ - матрицу выходного слоя.\n",
        "\n",
        "Каждому слову в словаре соответствует строка в матрице $U$ и столбец $V$.\n",
        "\n",
        "![skip-gram](https://image.ibb.co/khFXu9/Skip_gram.png)\n",
        "\n",
        "Что тут происходит? Слово отображается в эмбеддинг - строку $u_c$. Дальше этот эмбеддинг умножается на матрицу $V$. \n",
        "\n",
        "В итоге получаем набор числе $v_j^T u_c$ - степень похожести слова с номером $j$ и нашего слова.\n",
        "\n",
        "Преобразуем эти числа в что-то вроде вероятностей - воспользуемся функцией softmax: $P(i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}$.\n",
        "\n",
        "А дальше будем считать кросс-энтропийные потери:\n",
        "\n",
        "$$-\\sum_{-k \\leq j \\leq k, j \\neq 0} \\log \\frac{\\exp(v_{c+j}^T u_c)}{\\sum_{i=1}^{|V|} \\exp(v_i^T u_c)} \\to \\min_{U, V}.$$\n",
        "\n",
        "В итоге, вектор $u_c$ будет приближаться к векторам $v_{c_j}$ из его контекста.\n",
        "\n",
        "Реализуем это всё, чтобы разобраться.\n",
        "\n",
        "#### Генерация батчей\n",
        "\n",
        "Для начала нужно собрать контексты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocrsXgaynYPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_contexts(tokenized_texts, window_size):\n",
        "    contexts = []\n",
        "    for tokens in tokenized_texts:\n",
        "        for i in range(len(tokens)):\n",
        "            central_word = tokens[i]\n",
        "            context = [tokens[i + delta] for delta in range(-window_size, window_size + 1) \n",
        "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
        "\n",
        "            contexts.append((central_word, context))\n",
        "            \n",
        "    return contexts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQBa6yQ9BXjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contexts = build_contexts(tokenized_texts, window_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQNK-9SBdb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "06dd4ea0-fc70-459d-b35c-670ce4388411"
      },
      "source": [
        "contexts[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what', ['is', 'the']),\n",
              " ('is', ['what', 'the', 'step']),\n",
              " ('the', ['what', 'is', 'step', 'by']),\n",
              " ('step', ['is', 'the', 'by', 'step']),\n",
              " ('by', ['the', 'step', 'step', 'guide'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkmV-xQDyhRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "5727c9de-2d0e-4960-c3d2-30a571a84efb"
      },
      "source": [
        "tokenized_texts[:1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['what',\n",
              "  'is',\n",
              "  'the',\n",
              "  'step',\n",
              "  'by',\n",
              "  'step',\n",
              "  'guide',\n",
              "  'to',\n",
              "  'invest',\n",
              "  'in',\n",
              "  'share',\n",
              "  'market',\n",
              "  'in',\n",
              "  'india',\n",
              "  '?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbQKln_6yC4l",
        "colab_type": "text"
      },
      "source": [
        "Преобразуем слова в индексы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPRlKlLvUBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contexts = [(word2index.get(central_word, 0), [word2index.get(word, 0) for word in context]) \n",
        "            for central_word, context in contexts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUKUFwGZxomM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "b43e9c7e-9960-4681-bb24-801da38a2879"
      },
      "source": [
        "contexts[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, [4, 2]),\n",
              " (4, [3, 2, 1398]),\n",
              " (2, [3, 4, 1398, 66]),\n",
              " (1398, [4, 2, 66, 1398]),\n",
              " (66, [2, 1398, 1398, 2243])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYmrAi9gyIe-",
        "colab_type": "text"
      },
      "source": [
        "Реализуем генератор батчей для нашей нейронки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6opX5cEp8LxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def make_skip_gram_batchs_iter(contexts, window_size, num_skips, batch_size, epochs=2):\n",
        "    assert batch_size % num_skips == 0\n",
        "    assert num_skips <= 2 * window_size\n",
        "    \n",
        "    central_words = [word for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
        "    contexts = [context for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
        "    \n",
        "    batch_size = int(batch_size / num_skips)\n",
        "    batchs_count = int(math.ceil(len(contexts) / batch_size))\n",
        "    \n",
        "    print('Initializing batchs generator with {} batchs per epoch'.format(batchs_count))\n",
        "    \n",
        "    for _ in range(epochs):\n",
        "        indices = np.arange(len(contexts))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(batchs_count):\n",
        "            batch_begin, batch_end = i * batch_size, min((i + 1) * batch_size, len(contexts))\n",
        "            batch_indices = indices[batch_begin: batch_end]\n",
        "\n",
        "            batch_data, batch_labels = [], []\n",
        "\n",
        "            for data_ind in batch_indices:\n",
        "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
        "                \n",
        "                words_to_use = random.sample(context, num_skips)\n",
        "                batch_data.extend(words_to_use)\n",
        "                batch_labels.extend([central_word] * num_skips)\n",
        "            \n",
        "            yield batch_data, batch_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0D79MwB_gMe",
        "colab_type": "code",
        "outputId": "27906025-0e1d-4dbc-d5a0-dbbefcece0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "batch, labels = next(make_skip_gram_batchs_iter(contexts, window_size=2, num_skips=2, batch_size=32))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing batchs generator with 295262 batchs per epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex6qsZJ4fOaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27cf1a7a-b85f-4a00-a418-6ea27953d466"
      },
      "source": [
        "batch[3], labels[3]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DXjZS3JyQZh",
        "colab_type": "text"
      },
      "source": [
        "#### nn.Sequential\n",
        "\n",
        "Простейший способ реализовать модель на PyTorch - использовать модуль `nn.Sequential`. В нем нужно просто перечислить все слои, и он будет применять их последовательно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRw9Z4G__46O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Embedding(len(word2index), 32),\n",
        "    nn.Linear(32, len(word2index))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysn0DDpLyj1S",
        "colab_type": "text"
      },
      "source": [
        "Еще одна особенность pytorch, о которой до сих пор не говорили - поддержка вычислений на видеокарте. На видеокарте большинство нейронок считается гораздо быстрее благодаря высокой параллелизации. Сказать pytorch'у, чтобы он считал на видеокарте, очень просто:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfmaUi3Uy9YT",
        "colab_type": "code",
        "outputId": "f1784f5c-4f2b-43d2-9951-9cb572d4aac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(28634, 32)\n",
              "  (1): Linear(in_features=32, out_features=28634, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3c3UEa2zHhk",
        "colab_type": "text"
      },
      "source": [
        "либо"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHxAg5ZWzEKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHi1CL2pzxOg",
        "colab_type": "text"
      },
      "source": [
        "Создать тензоры на видеокарте можно, например, так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycx1O3_SzvmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = torch.cuda.LongTensor(batch)\n",
        "labels = torch.cuda.LongTensor(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtLMvOO2z3c8",
        "colab_type": "text"
      },
      "source": [
        "Заставить модель посчитать значение можно так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9wTpewTz3Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = model(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWJmDy_uzJgD",
        "colab_type": "text"
      },
      "source": [
        "Теперь нам нужна функция потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7rlD62_ykYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss().cuda() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxLBiBua0OZM",
        "colab_type": "text"
      },
      "source": [
        "Посчитать значение можно так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCaTB5cc0GVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = loss_function(logits, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAwx-pck0RxX",
        "colab_type": "text"
      },
      "source": [
        "А теперь, конечно же, backprop!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWt6gL0_0Npp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJkDOl6szRLm",
        "colab_type": "text"
      },
      "source": [
        "И, наконец, оптимизатор.\n",
        "\n",
        "Будем использовать Adam. Интерфейс - передать список оптимизируемых параметров и learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-b5CIARzQ6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju5lO0Xi0hsV",
        "colab_type": "text"
      },
      "source": [
        "Оптимизация идет просто - нужно вызвать `step()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9QK7nHu0Zw8",
        "colab_type": "code",
        "outputId": "f72bf4f9-4af4-4f21-a6b8-f980de3eb685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "print(model[0].weight)\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "print(model[0].weight)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.9380,  0.0858,  0.4901,  ..., -0.9878,  0.0675,  0.0159],\n",
            "        [ 0.0290, -0.1826, -0.0382,  ..., -0.1245,  0.0462,  0.2549],\n",
            "        [ 1.2472,  0.0653, -0.1358,  ...,  0.1408,  1.1871, -0.5609],\n",
            "        ...,\n",
            "        [ 0.1557,  0.8079, -0.4245,  ..., -1.3827, -1.5849, -0.0385],\n",
            "        [-0.1780,  1.1945,  0.6401,  ...,  0.8814, -0.1729, -0.3450],\n",
            "        [ 0.7539,  1.6006,  1.3302,  ...,  0.3514, -1.3323,  0.3459]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.9380,  0.0858,  0.4901,  ..., -0.9878,  0.0675,  0.0159],\n",
            "        [ 0.0190, -0.1726, -0.0282,  ..., -0.1345,  0.0362,  0.2649],\n",
            "        [ 1.2372,  0.0753, -0.1258,  ...,  0.1308,  1.1771, -0.5509],\n",
            "        ...,\n",
            "        [ 0.1557,  0.8079, -0.4245,  ..., -1.3827, -1.5849, -0.0385],\n",
            "        [-0.1780,  1.1945,  0.6401,  ...,  0.8814, -0.1729, -0.3450],\n",
            "        [ 0.7539,  1.6006,  1.3302,  ...,  0.3514, -1.3323,  0.3459]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnxyk1ew0pSk",
        "colab_type": "text"
      },
      "source": [
        "И последнее - нужно обнулить градиенты!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMsuvEP90svi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PibTw33Azg7q",
        "colab_type": "text"
      },
      "source": [
        "#### Реализация обучения skip-gram модели\n",
        "\n",
        "Наконец, напишем цикл обучения - как уже было с линейной регрессией.\n",
        "\n",
        " **Задание** Заполните цикл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewGMgYTXANzz",
        "colab_type": "code",
        "outputId": "8c8f515c-5ef0-4f7e-cb60-e69838485aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "for step, (batch, labels) in enumerate(make_skip_gram_batchs_iter(contexts, window_size=2,\n",
        "                                                                  num_skips=4, batch_size=256,\n",
        "                                                                  epochs=20)):\n",
        "    #<1. convert data to tensors>\n",
        "\n",
        "    batch = torch.cuda.LongTensor(batch)\n",
        "    labels = torch.cuda.LongTensor(labels)\n",
        "     \n",
        "    #<2. make forward pass>\n",
        "\n",
        "    batch_res = model(batch)\n",
        "    logits = F.log_softmax(batch_res)\n",
        "\n",
        "    #<3. make backward pass>\n",
        " \n",
        "    loss = loss_function(logits, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    #<4. apply optimizer>\n",
        "    optimizer.step()\n",
        "\n",
        "    #<5. zero grads>\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing batchs generator with 73816 batchs per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step = 1000, Avg Loss = 8.7727, Time = 4.65s\n",
            "Step = 2000, Avg Loss = 7.4169, Time = 2.74s\n",
            "Step = 3000, Avg Loss = 7.1168, Time = 2.76s\n",
            "Step = 4000, Avg Loss = 6.9589, Time = 2.75s\n",
            "Step = 5000, Avg Loss = 6.8673, Time = 2.75s\n",
            "Step = 6000, Avg Loss = 6.8312, Time = 2.74s\n",
            "Step = 7000, Avg Loss = 6.8047, Time = 2.75s\n",
            "Step = 8000, Avg Loss = 6.7536, Time = 2.74s\n",
            "Step = 9000, Avg Loss = 6.7344, Time = 2.80s\n",
            "Step = 10000, Avg Loss = 6.7189, Time = 2.74s\n",
            "Step = 11000, Avg Loss = 6.6907, Time = 2.75s\n",
            "Step = 12000, Avg Loss = 6.6922, Time = 2.73s\n",
            "Step = 13000, Avg Loss = 6.6831, Time = 2.74s\n",
            "Step = 14000, Avg Loss = 6.6840, Time = 2.76s\n",
            "Step = 15000, Avg Loss = 6.6710, Time = 2.76s\n",
            "Step = 16000, Avg Loss = 6.6677, Time = 2.77s\n",
            "Step = 17000, Avg Loss = 6.6518, Time = 2.75s\n",
            "Step = 18000, Avg Loss = 6.6587, Time = 2.74s\n",
            "Step = 19000, Avg Loss = 6.6546, Time = 2.74s\n",
            "Step = 20000, Avg Loss = 6.6708, Time = 2.74s\n",
            "Step = 21000, Avg Loss = 6.6154, Time = 2.74s\n",
            "Step = 22000, Avg Loss = 6.6106, Time = 2.78s\n",
            "Step = 23000, Avg Loss = 6.6267, Time = 2.73s\n",
            "Step = 24000, Avg Loss = 6.6189, Time = 2.75s\n",
            "Step = 25000, Avg Loss = 6.6295, Time = 2.75s\n",
            "Step = 26000, Avg Loss = 6.6056, Time = 2.76s\n",
            "Step = 27000, Avg Loss = 6.6323, Time = 2.78s\n",
            "Step = 28000, Avg Loss = 6.6133, Time = 2.76s\n",
            "Step = 29000, Avg Loss = 6.6045, Time = 2.75s\n",
            "Step = 30000, Avg Loss = 6.6046, Time = 2.77s\n",
            "Step = 31000, Avg Loss = 6.6055, Time = 2.78s\n",
            "Step = 32000, Avg Loss = 6.5840, Time = 2.74s\n",
            "Step = 33000, Avg Loss = 6.5823, Time = 2.75s\n",
            "Step = 34000, Avg Loss = 6.5997, Time = 2.73s\n",
            "Step = 35000, Avg Loss = 6.5676, Time = 2.74s\n",
            "Step = 36000, Avg Loss = 6.5899, Time = 2.76s\n",
            "Step = 37000, Avg Loss = 6.5871, Time = 2.79s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fe1761251a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#<4. apply optimizer>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqq9kee41L4P",
        "colab_type": "text"
      },
      "source": [
        "#### Анализ\n",
        "\n",
        "Получить эмбеддинги можно скаставав такое заклинание:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWsYkNn-Hnl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = model[0].weight.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZtxY2D01RB6",
        "colab_type": "text"
      },
      "source": [
        "Проверим, получилось ли хоть сколько-то адекватно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhDwuhDSHEDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def most_similar(embeddings, index2word, word2index, word):\n",
        "    word_emb = embeddings[word2index[word]]\n",
        "    \n",
        "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
        "    top10 = np.argsort(similarities)[-10:]\n",
        "    \n",
        "    return [index2word[index] for index in reversed(top10)]\n",
        "\n",
        "most_similar(embeddings, index2word, word2index, 'people')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VS1x-mO1WKS",
        "colab_type": "text"
      },
      "source": [
        "И визуализируем!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuXv2HxsAecb",
        "colab_type": "code",
        "outputId": "379894c1-2b88-47e7-ed21-9cd6cb446f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        }
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    tsne = TSNE(n_components=2, verbose=100)\n",
        "    return scale(tsne.fit_transform(word_vectors))\n",
        "    \n",
        "    \n",
        "def visualize_embeddings(embeddings, index2word, word_count):\n",
        "    word_vectors = embeddings[1: word_count + 1]\n",
        "    words = index2word[1: word_count + 1]\n",
        "    \n",
        "    word_tsne = get_tsne_projection(word_vectors)\n",
        "    draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)\n",
        "    \n",
        "    \n",
        "visualize_embeddings(embeddings, index2word, 400)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 400 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 400 samples in 0.015s...\n",
            "[t-SNE] Computed conditional probabilities for sample 400 / 400\n",
            "[t-SNE] Mean sigma: 2.126468\n",
            "[t-SNE] Computed conditional probabilities in 0.022s\n",
            "[t-SNE] Iteration 50: error = 78.6430283, gradient norm = 0.4367049 (50 iterations in 5.830s)\n",
            "[t-SNE] Iteration 100: error = 82.1829376, gradient norm = 0.4437555 (50 iterations in 4.358s)\n",
            "[t-SNE] Iteration 150: error = 82.6946106, gradient norm = 0.4235014 (50 iterations in 5.401s)\n",
            "[t-SNE] Iteration 200: error = 86.8661041, gradient norm = 0.4110603 (50 iterations in 4.210s)\n",
            "[t-SNE] Iteration 250: error = 86.0581818, gradient norm = 0.3911677 (50 iterations in 4.698s)\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 86.058182\n",
            "[t-SNE] Iteration 300: error = 1.9904560, gradient norm = 0.0052407 (50 iterations in 3.634s)\n",
            "[t-SNE] Iteration 350: error = 1.8428710, gradient norm = 0.0016334 (50 iterations in 4.242s)\n",
            "[t-SNE] Iteration 400: error = 1.7708359, gradient norm = 0.0020615 (50 iterations in 3.080s)\n",
            "[t-SNE] Iteration 450: error = 1.7316747, gradient norm = 0.0008864 (50 iterations in 4.234s)\n",
            "[t-SNE] Iteration 500: error = 1.7183821, gradient norm = 0.0005658 (50 iterations in 3.736s)\n",
            "[t-SNE] Iteration 550: error = 1.7103953, gradient norm = 0.0005242 (50 iterations in 3.942s)\n",
            "[t-SNE] Iteration 600: error = 1.6999166, gradient norm = 0.0007718 (50 iterations in 11.352s)\n",
            "[t-SNE] Iteration 650: error = 1.6887898, gradient norm = 0.0009211 (50 iterations in 48.450s)\n",
            "[t-SNE] Iteration 700: error = 1.6803436, gradient norm = 0.0007440 (50 iterations in 53.425s)\n",
            "[t-SNE] Iteration 750: error = 1.6733514, gradient norm = 0.0004791 (50 iterations in 63.147s)\n",
            "[t-SNE] Iteration 800: error = 1.6705536, gradient norm = 0.0003115 (50 iterations in 60.199s)\n",
            "[t-SNE] Iteration 850: error = 1.6669818, gradient norm = 0.0003396 (50 iterations in 63.673s)\n",
            "[t-SNE] Iteration 900: error = 1.6624022, gradient norm = 0.0007976 (50 iterations in 67.109s)\n",
            "[t-SNE] Iteration 950: error = 1.6596601, gradient norm = 0.0002709 (50 iterations in 71.079s)\n",
            "[t-SNE] Iteration 1000: error = 1.6565783, gradient norm = 0.0001015 (50 iterations in 73.951s)\n",
            "[t-SNE] KL divergence after 1000 iterations: 1.656578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"121cdb30-8cbe-48a2-abac-9b7945439b87\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"822770b9-8620-47bc-9852-5fba8810a81d\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1020\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1037\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1042\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1003\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1007\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{\"overlay\":{\"id\":\"1047\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1036\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"?\",\"the\",\"what\",\"is\",\"a\",\"i\",\"to\",\"in\",\"how\",\"of\",\"do\",\"are\",\"and\",\"for\",\",\",\"can\",\"you\",\"why\",\"it\",\"my\",\"does\",\"best\",\"on\",\".\",\"or\",\"have\",\"if\",\"be\",\"with\",\"which\",\"that\",\"an\",\"some\",\"should\",\"'s\",\"get\",\"from\",\")\",\"your\",\"(\",\"like\",\"when\",\"at\",\"india\",\"good\",\"who\",\"there\",\"will\",\"as\",\"would\",\"people\",\"not\",\"n't\",\"about\",\"``\",\"''\",\"between\",\"one\",\"did\",\"any\",\"we\",\"me\",\"where\",\"most\",\"was\",\"by\",\"make\",\"so\",\"they\",\"this\",\"am\",\"after\",\"way\",\":\",\"has\",\"use\",\"much\",\"difference\",\"time\",\"life\",\"their\",\"know\",\"work\",\"many\",\"but\",\"than\",\"more\",\"all\",\"want\",\"quora\",\"someone\",\"learn\",\"find\",\"other\",\"think\",\"new\",\"better\",\"job\",\"indian\",\"out\",\"money\",\"mean\",\"become\",\"ever\",\"world\",\"without\",\"he\",\"start\",\"take\",\"us\",\"up\",\"first\",\"feel\",\"year\",\"into\",\"go\",\"online\",\"used\",\"engineering\",\"could\",\"love\",\"'m\",\"person\",\"were\",\"possible\",\"day\",\"buy\",\"things\",\"being\",\"need\",\"business\",\"using\",\"them\",\"really\",\"trump\",\"girl\",\"'\",\"her\",\"his\",\"years\",\"different\",\"long\",\"phone\",\"google\",\"company\",\"been\",\"old\",\"only\",\"no\",\"now\",\"just\",\"2\",\"app\",\"college\",\"facebook\",\"number\",\"free\",\"books\",\"2016\",\"movie\",\"still\",\"its\",\"account\",\"ca\",\"women\",\"book\",\"english\",\"while\",\"she\",\"had\",\"change\",\"ways\",\"computer\",\"thing\",\"examples\",\"data\",\"country\",\"over\",\"see\",\"android\",\"help\",\"science\",\"live\",\"school\",\"software\",\"before\",\"&\",\"language\",\"same\",\"going\",\"bad\",\"sex\",\"student\",\"stop\",\"university\",\"happen\",\"back\",\"made\",\"3\",\"1\",\"study\",\"our\",\"two\",\"through\",\"system\",\"name\",\"say\",\"real\",\"during\",\"prepare\",\"water\",\"iphone\",\"website\",\"top\",\"car\",\"questions\",\"important\",\"men\",\"give\",\"getting\",\"anyone\",\"companies\",\"high\",\"black\",\"card\",\"read\",\"programming\",\"war\",\"learning\",\"10\",\"5\",\"\\u2019\",\"exam\",\"[\",\"then\",\"]\",\"even\",\"movies\",\"china\",\"mobile\",\"cost\",\"donald\",\"right\",\"doing\",\"friend\",\"him\",\"working\",\"under\",\"come\",\"president\",\"own\",\"question\",\"career\",\"experience\",\"bank\",\"true\",\"friends\",\"guy\",\"word\",\"hair\",\"home\",\"video\",\"having\",\"look\",\"usa\",\"tell\",\"man\",\"social\",\"web\",\"interview\",\"very\",\"engineer\",\"write\",\"game\",\"government\",\"weight\",\"earth\",\"girls\",\"service\",\"food\",\"students\",\"play\",\"countries\",\"human\",\"place\",\"future\",\"improve\",\"off\",\"big\",\"days\",\"happens\",\"'ve\",\"done\",\"class\",\"eat\",\"tv\",\"process\",\"got\",\"state\",\"average\",\"s\",\"meaning\",\"relationship\",\"music\",\"too\",\"math\",\"create\",\"instagram\",\"every\",\"history\",\"last\",\"pay\",\"windows\",\"4\",\"white\",\"watch\",\"%\",\"salary\",\"body\",\"power\",\"safe\",\"clinton\",\"ask\",\"age\",\"laptop\",\"makes\",\"$\",\"each\",\"hard\",\"lose\",\"american\",\"delhi\",\"youtube\",\"energy\",\"worth\",\"earn\",\"states\",\"against\",\"win\",\"girlfriend\",\"great\",\"keep\",\"test\",\"god\",\"hillary\",\"compare\",\"market\",\"differences\",\"making\",\"considered\",\"something\",\"answer\",\"apply\",\"myself\",\"mba\",\"tips\",\"around\",\"never\",\"next\",\"always\",\"mechanical\",\"another\",\"united\",\"java\",\"increase\",\"c\",\"such\",\"course\",\"jobs\",\"download\",\"song\",\"parents\",\"kind\",\"internet\",\"common\",\"review\",\"woman\",\"code\",\"design\",\"per\",\"employees\",\"end\",\"development\",\"chinese\",\"series\",\"score\",\"interesting\",\"degree\",\"month\",\"travel\",\"show\",\"management\",\"months\",\"able\",\"believe\",\"open\",\"program\",\"living\",\"looking\",\"because\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[400]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[400]}},\"selected\":{\"id\":\"1048\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1049\",\"type\":\"UnionRenderers\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"}},\"id\":\"1038\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1035\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1036\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1038\",\"type\":\"CDSView\"}},\"id\":\"1037\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1039\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"Selection\"},{\"attributes\":{\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1042\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1047\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"},{\"id\":\"1039\",\"type\":\"HoverTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
              "  var render_items = [{\"docid\":\"822770b9-8620-47bc-9852-5fba8810a81d\",\"roots\":{\"1002\":\"121cdb30-8cbe-48a2-abac-9b7945439b87\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGfhLR6x8D3r",
        "colab_type": "text"
      },
      "source": [
        "### Continuous Bag of Words (CBoW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UuVr2IsaYhX",
        "colab_type": "text"
      },
      "source": [
        "Альтернативный вариант модели:\n",
        "\n",
        "![](https://image.ibb.co/jnsW49/CBOW.png)\n",
        "\n",
        "Теперь по *сумме* контекстных векторов предсказывается вектор центрального слова.\n",
        "\n",
        "**Задание** Реализуйте часть функции для генерации батчей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5VmnnjtsXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_cbow_batchs_iter(contexts, window_size, batch_size, epochs=2):\n",
        "    data = np.array([context for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
        "    labels = np.array([word for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
        "        \n",
        "    batchs_count = int(math.ceil(len(data) / batch_size))\n",
        "    \n",
        "    print('Initializing batchs generator with {} batchs per epoch'.format(batchs_count))\n",
        "    \n",
        "    for _ in range(epochs):\n",
        "        indices = np.arange(len(data))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(batchs_count):\n",
        "            batch_begin, batch_end = i * batch_size, min((i + 1) * batch_size, len(contexts))\n",
        "            batch_indices = indices[batch_begin: batch_end]\n",
        "            batch_data, batch_labels = [], []\n",
        "\n",
        "            for data_ind in batch_indices:\n",
        "                central_word, context = labels[data_ind], data[data_ind]\n",
        "                batch_labels.extend([central_word])\n",
        "                batch_data.extend(context.reshape(-1, 2 * window_size))\n",
        "            \n",
        "            yield batch_data, batch_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0H3rJMgcsYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ad14bc34-52a9-43e1-bf23-d54f0362b3bb"
      },
      "source": [
        "batch, labels = next(make_cbow_batchs_iter(contexts, window_size=2, batch_size=32))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing batchs generator with 147631 batchs per epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-FwSVXEfEGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "281591a2-1a96-4d5c-e76e-6a6e9aafbb30"
      },
      "source": [
        "batch[3], labels[3]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1224,   13,  108, 1865]), 278)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9HkY-VO61n3",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на альтернативный вариант создания модели - им мы будем пользоваться чаще всего - отнаследоваться от `nn.Module`. Схематично её использование выглядит так:\n",
        "\n",
        "```python\n",
        "class MyNetModel(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyNetModel, self).__init__()\n",
        "        <initialize layers>\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        <apply layers>\n",
        "        return final_output\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mHKLbMwx4c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CBoWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_layer = nn.Linear(embedding_dim, vocab_size, bias)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = torch.mean(self.embeddings(inputs), dim=1)\n",
        "        out = self.out_layer(emb)\n",
        "        output = F.log_softmax(out)\n",
        "        return output\n",
        "      \n",
        "model = CBoWModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiIgaofEyyJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "632e912c-dabd-412a-bcbe-01b8d5ed4b2d"
      },
      "source": [
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, (batch, labels) in enumerate(make_cbow_batchs_iter(contexts, window_size=2,\n",
        "                                                             batch_size=256, epochs=20)):\n",
        "    #<1. convert data to tensors>\n",
        "\n",
        "    batch = torch.cuda.LongTensor(batch)\n",
        "    labels = torch.cuda.LongTensor(labels)\n",
        "     \n",
        "    #<2. make forward pass>\n",
        "\n",
        "    batch_res = model(batch)\n",
        "    logits = F.log_softmax(batch_res)\n",
        "\n",
        "    #<3. make backward pass>\n",
        " \n",
        "    loss = loss_function(logits, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    #<4. apply optimizer>\n",
        "    optimizer.step()\n",
        "\n",
        "    #<5. zero grads>\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing batchs generator with 18454 batchs per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step = 1000, Avg Loss = 5.2555, Time = 8.21s\n",
            "Step = 2000, Avg Loss = 5.2457, Time = 3.54s\n",
            "Step = 3000, Avg Loss = 5.2468, Time = 3.59s\n",
            "Step = 4000, Avg Loss = 5.2354, Time = 3.54s\n",
            "Step = 5000, Avg Loss = 5.2275, Time = 3.55s\n",
            "Step = 6000, Avg Loss = 5.2140, Time = 3.55s\n",
            "Step = 7000, Avg Loss = 5.2169, Time = 3.55s\n",
            "Step = 8000, Avg Loss = 5.2066, Time = 3.55s\n",
            "Step = 9000, Avg Loss = 5.2026, Time = 3.54s\n",
            "Step = 10000, Avg Loss = 5.1877, Time = 3.61s\n",
            "Step = 11000, Avg Loss = 5.1786, Time = 3.53s\n",
            "Step = 12000, Avg Loss = 5.1699, Time = 3.53s\n",
            "Step = 13000, Avg Loss = 5.1509, Time = 3.54s\n",
            "Step = 14000, Avg Loss = 5.1579, Time = 3.57s\n",
            "Step = 15000, Avg Loss = 5.1514, Time = 3.61s\n",
            "Step = 16000, Avg Loss = 5.1471, Time = 3.60s\n",
            "Step = 17000, Avg Loss = 5.1343, Time = 3.54s\n",
            "Step = 18000, Avg Loss = 5.1194, Time = 3.53s\n",
            "Step = 19000, Avg Loss = 5.0961, Time = 3.70s\n",
            "Step = 20000, Avg Loss = 5.0631, Time = 3.61s\n",
            "Step = 21000, Avg Loss = 5.0583, Time = 3.52s\n",
            "Step = 22000, Avg Loss = 5.0606, Time = 3.55s\n",
            "Step = 23000, Avg Loss = 5.0454, Time = 3.53s\n",
            "Step = 24000, Avg Loss = 5.0594, Time = 3.55s\n",
            "Step = 25000, Avg Loss = 5.0571, Time = 3.54s\n",
            "Step = 26000, Avg Loss = 5.0445, Time = 3.54s\n",
            "Step = 27000, Avg Loss = 5.0388, Time = 3.58s\n",
            "Step = 28000, Avg Loss = 5.0291, Time = 3.52s\n",
            "Step = 29000, Avg Loss = 5.0429, Time = 3.52s\n",
            "Step = 30000, Avg Loss = 5.0414, Time = 3.57s\n",
            "Step = 31000, Avg Loss = 5.0162, Time = 3.62s\n",
            "Step = 32000, Avg Loss = 5.0312, Time = 3.69s\n",
            "Step = 33000, Avg Loss = 5.0039, Time = 3.70s\n",
            "Step = 34000, Avg Loss = 5.0233, Time = 3.55s\n",
            "Step = 35000, Avg Loss = 5.0185, Time = 3.52s\n",
            "Step = 36000, Avg Loss = 5.0092, Time = 3.52s\n",
            "Step = 37000, Avg Loss = 4.9900, Time = 3.75s\n",
            "Step = 38000, Avg Loss = 4.9460, Time = 3.51s\n",
            "Step = 39000, Avg Loss = 4.9407, Time = 3.57s\n",
            "Step = 40000, Avg Loss = 4.9375, Time = 3.55s\n",
            "Step = 41000, Avg Loss = 4.9399, Time = 3.54s\n",
            "Step = 42000, Avg Loss = 4.9527, Time = 3.54s\n",
            "Step = 43000, Avg Loss = 4.9523, Time = 3.62s\n",
            "Step = 44000, Avg Loss = 4.9444, Time = 3.52s\n",
            "Step = 45000, Avg Loss = 4.9457, Time = 3.51s\n",
            "Step = 46000, Avg Loss = 4.9410, Time = 3.52s\n",
            "Step = 47000, Avg Loss = 4.9480, Time = 3.53s\n",
            "Step = 48000, Avg Loss = 4.9406, Time = 3.56s\n",
            "Step = 49000, Avg Loss = 4.9337, Time = 3.61s\n",
            "Step = 50000, Avg Loss = 4.9351, Time = 3.61s\n",
            "Step = 51000, Avg Loss = 4.9236, Time = 3.51s\n",
            "Step = 52000, Avg Loss = 4.9489, Time = 3.51s\n",
            "Step = 53000, Avg Loss = 4.9319, Time = 3.52s\n",
            "Step = 54000, Avg Loss = 4.9459, Time = 3.59s\n",
            "Step = 55000, Avg Loss = 4.9268, Time = 3.52s\n",
            "Step = 56000, Avg Loss = 4.8831, Time = 3.72s\n",
            "Step = 57000, Avg Loss = 4.8727, Time = 3.53s\n",
            "Step = 58000, Avg Loss = 4.8631, Time = 3.53s\n",
            "Step = 59000, Avg Loss = 4.8776, Time = 3.55s\n",
            "Step = 60000, Avg Loss = 4.8753, Time = 3.60s\n",
            "Step = 61000, Avg Loss = 4.8749, Time = 3.52s\n",
            "Step = 62000, Avg Loss = 4.8676, Time = 3.52s\n",
            "Step = 63000, Avg Loss = 4.8722, Time = 3.52s\n",
            "Step = 64000, Avg Loss = 4.8857, Time = 3.58s\n",
            "Step = 65000, Avg Loss = 4.8712, Time = 3.58s\n",
            "Step = 66000, Avg Loss = 4.8681, Time = 3.58s\n",
            "Step = 67000, Avg Loss = 4.8698, Time = 3.63s\n",
            "Step = 68000, Avg Loss = 4.8670, Time = 3.52s\n",
            "Step = 69000, Avg Loss = 4.8905, Time = 3.52s\n",
            "Step = 70000, Avg Loss = 4.8678, Time = 3.51s\n",
            "Step = 71000, Avg Loss = 4.8818, Time = 3.58s\n",
            "Step = 72000, Avg Loss = 4.8738, Time = 3.52s\n",
            "Step = 73000, Avg Loss = 4.8743, Time = 3.54s\n",
            "Step = 74000, Avg Loss = 4.8548, Time = 3.69s\n",
            "Step = 75000, Avg Loss = 4.8122, Time = 3.52s\n",
            "Step = 76000, Avg Loss = 4.8113, Time = 3.52s\n",
            "Step = 77000, Avg Loss = 4.8132, Time = 3.58s\n",
            "Step = 78000, Avg Loss = 4.8146, Time = 3.52s\n",
            "Step = 79000, Avg Loss = 4.8291, Time = 3.51s\n",
            "Step = 80000, Avg Loss = 4.8160, Time = 3.51s\n",
            "Step = 81000, Avg Loss = 4.8137, Time = 3.55s\n",
            "Step = 82000, Avg Loss = 4.8297, Time = 3.60s\n",
            "Step = 83000, Avg Loss = 4.8321, Time = 3.56s\n",
            "Step = 84000, Avg Loss = 4.8314, Time = 3.60s\n",
            "Step = 85000, Avg Loss = 4.8335, Time = 3.52s\n",
            "Step = 86000, Avg Loss = 4.8292, Time = 3.52s\n",
            "Step = 87000, Avg Loss = 4.8232, Time = 3.52s\n",
            "Step = 88000, Avg Loss = 4.8243, Time = 3.59s\n",
            "Step = 89000, Avg Loss = 4.8400, Time = 3.53s\n",
            "Step = 90000, Avg Loss = 4.8268, Time = 3.54s\n",
            "Step = 91000, Avg Loss = 4.8247, Time = 3.53s\n",
            "Step = 92000, Avg Loss = 4.8310, Time = 3.51s\n",
            "Step = 93000, Avg Loss = 4.7745, Time = 3.69s\n",
            "Step = 94000, Avg Loss = 4.7715, Time = 3.58s\n",
            "Step = 95000, Avg Loss = 4.7546, Time = 3.51s\n",
            "Step = 96000, Avg Loss = 4.7721, Time = 3.53s\n",
            "Step = 97000, Avg Loss = 4.7805, Time = 3.50s\n",
            "Step = 98000, Avg Loss = 4.7860, Time = 3.54s\n",
            "Step = 99000, Avg Loss = 4.7800, Time = 3.62s\n",
            "Step = 100000, Avg Loss = 4.7935, Time = 3.58s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ac71e1f7931a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#<1. convert data to tensors>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNcMEcxEoC-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "a9c12bd6-2c45-4baf-920b-9f0c7c1627b1"
      },
      "source": [
        "embeddings = model.embeddings.weight.cpu().data.numpy()\n",
        "most_similar(embeddings, index2word, word2index, 'people')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['people',\n",
              " 'guys',\n",
              " 'quorans',\n",
              " 'americans',\n",
              " 'girls',\n",
              " 'women',\n",
              " 'indians',\n",
              " 'men',\n",
              " 'psychopaths',\n",
              " 'hindus']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTEWcyYmvips",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CON4VOyG3iET",
        "colab_type": "text"
      },
      "source": [
        "### Negative Sampling\n",
        "\n",
        "Что сейчас самое тяжелое? Вычисление softmax и применение градиентов ко всем словам в $V$.\n",
        "\n",
        "Один из способов справиться с этим - использовать *Negative Sampling*.\n",
        "\n",
        "По сути, вместо предсказания индекса слова по контексту предсказывается вероятность того, что такое слово может быть в таком контексте: $P(D=1|w,c)$.\n",
        "\n",
        "Можно использовать обычную сигмоиду для получения данной вероятности: \n",
        "$$P(D=1|w, c) = \\sigma(v_w^T u_c) = \\frac 1 {1 + \\exp(-v^T_w u_c)}.$$\n",
        "\n",
        "Процесс обучения тогда выглядит так: для каждой пары слово и его контекст генерируем набор отрицательных примеров:\n",
        "\n",
        "![Negative Sampling](https://image.ibb.co/dnOUDH/Negative_Sampling.png)\n",
        "\n",
        "Для CBoW функция потерь будет выглядеть так:\n",
        "$$-\\log \\sigma(v_c^T u_c) - \\sum_{k=1}^K \\log \\sigma(-\\tilde v_k^T u_c),$$\n",
        "где $v_c$ - вектор центрального слова, $u_c$ - вектор контекста (сумма контекстных векторов), $\\tilde v_1, \\ldots, \\tilde v_K$ - сэмплированные негативные примеры.\n",
        "\n",
        "Сравните эту формулу с обычным CBoW:\n",
        "$$-v_c^T u_c + \\log \\sum_{i=1}^{|V|} \\exp(v_i^T u_c).$$\n",
        "\n",
        "Обычно слова сэмплируются из $U^{3/4}$, где $U$ - униграмное распределение, т.е частоты появления слова делённые на суммарое число слов. \n",
        "\n",
        "Частотности мы уже считали: они получаются в `Counter(words)`. Достаточно просто преобразовать их в вероятности и домножить эти вероятности на $\\frac 3 4$. Почему $\\frac 3 4$? Некоторую интуицию можно найти в следующем примере:\n",
        "\n",
        "$$P(\\text{is}) = 0.9, \\ P(\\text{is})^{3/4} = 0.92$$\n",
        "$$P(\\text{Constitution}) = 0.09, \\ P(\\text{Constitution})^{3/4} = 0.16$$\n",
        "$$P(\\text{bombastic}) = 0.01, \\ P(\\text{bombastic})^{3/4} = 0.032$$\n",
        "\n",
        "Вероятность для высокочастотных слов особо не увеличилась (относительно), зато низкочастотные будут выпадать с заметно большей вероятностей.\n",
        "\n",
        "**Задание** Реализуйте свой Negative Sampling.\n",
        "\n",
        "Для начала зададим распределение для сэмплирования:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcX4vRBLlXy6",
        "colab_type": "code",
        "outputId": "0e1f8030-75f8-4696-d5b8-33ecb7bf8a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "source": [
        "words_sum_count = sum(words_counter.values())\n",
        "word_distribution = np.array([(words_counter[word] / words_sum_count) ** (3 / 4) for word in index2word])\n",
        "word_distribution /= word_distribution.sum()\n",
        "\n",
        "indices = np.arange(len(word_distribution))\n",
        "\n",
        "np.random.choice(indices, p=word_distribution, size=(32, 5))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   36,  4061, 17274,  1984,  6062],\n",
              "       [    2,  1078,   805, 16036,   200],\n",
              "       [   66,     1,   187,  6641,  1353],\n",
              "       [ 6198,   155,    70,     1,   225],\n",
              "       [21163,   387,  2946, 10422,    28],\n",
              "       [   59,   451,   917, 21978,     1],\n",
              "       [ 1557,     2, 10108,    57,  3302],\n",
              "       [  588, 11829,     7,   537,   683],\n",
              "       [ 1830,   111,     1,  4008,    31],\n",
              "       [ 1630,  1203,    16,  1921,   913],\n",
              "       [11212,  2098,  2075,   855,  4035],\n",
              "       [ 6696,  1175,    44,  5308,  2873],\n",
              "       [15381,  2182,    29,     6,     7],\n",
              "       [    2,    96,  3797, 17482,  6718],\n",
              "       [ 1655,   684,   367,  1896,   445],\n",
              "       [ 2221,   207,  4143,   417,     1],\n",
              "       [  192,    62,    41,  2568,     8],\n",
              "       [   75,    16,     7,    87,  1064],\n",
              "       [ 1006,  4214,  5655,  2422,  2322],\n",
              "       [ 2015,    12,    19,   692,  1533],\n",
              "       [ 4409,    23,  2733,     5,   929],\n",
              "       [  338,    70,  9198,    10,   958],\n",
              "       [    4,    26,  5675,   158, 16194],\n",
              "       [ 4515,  1970, 10650,   154,  1871],\n",
              "       [   47,    86,     5, 22404,     5],\n",
              "       [   40,  1397, 14282,    98, 13158],\n",
              "       [   40,  4192,     4, 25734,   198],\n",
              "       [    8,   103,   115,  1006,   148],\n",
              "       [ 2948, 16527,  1782,  2832,  3058],\n",
              "       [    1,  1180,    20,  2359,     1],\n",
              "       [ 3297,  1302,   781,     3, 20161],\n",
              "       [  253,  1024, 19360,    27,     1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2pzsue16Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class NegativeSamplingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.loss_function = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    def forward(self, inputs, targets, num_samples):\n",
        "        '''\n",
        "        inputs: (batch_size, context_size)\n",
        "        targets: (batch_size)\n",
        "        num_samples: int\n",
        "        '''\n",
        "        \n",
        "        batch_size, context_size = inputs.shape\n",
        "\n",
        "        u_c = torch.sum(self.embeddings(inputs), dim=1)\n",
        "        v_c = self.embeddings(targets)\n",
        "        \n",
        "        indices = np.arange(len(word_distribution))\n",
        "        sample = torch.cuda.LongTensor(np.random.choice(indices,\n",
        "                                                        p=word_distribution,\n",
        "                                                        size=(batch_size, num_samples)))\n",
        "        \n",
        "        neg_embeddings = (-1) * self.embeddings(sample)\n",
        "\n",
        "        positive_scores = F.logsigmoid(torch.sum(u_c * v_c, dim = 1))\n",
        "        negative_scores = torch.sum(F.logsigmoid(torch.sum(u_c.reshape(batch_size, 1, -1) * neg_embeddings, dim=2)), dim=1)\n",
        "\n",
        "        loss = - negative_scores - positive_scores\n",
        "        return torch.mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wz2iRanqzlq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ea0662d-5213-4ca3-acb0-5c0001a03801"
      },
      "source": [
        "model = NegativeSamplingModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  \n",
        "\n",
        "loss_every_nsteps = 1000\n",
        "total_loss = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for step, (batch, labels) in enumerate(make_cbow_batchs_iter(contexts,\n",
        "                                                             window_size=2,\n",
        "                                                             batch_size=256,\n",
        "                                                             epochs=20)):\n",
        "#     <1. convert data to tensors>\n",
        "    batch = torch.cuda.LongTensor(batch)\n",
        "    labels = torch.cuda.LongTensor(labels)\n",
        "#     <2. make forward pass>\n",
        "    loss = model.forward(inputs=batch, targets=labels, num_samples=6)\n",
        "#     <3. make backward pass>\n",
        "    loss.backward()\n",
        "#     <4. apply optimizer>\n",
        "    optimizer.step()\n",
        "#     <5. zero grads>|\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    if step != 0 and step % loss_every_nsteps == 0:\n",
        "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
        "                                                                    time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing batchs generator with 18454 batchs per epoch\n",
            "Step = 1000, Avg Loss = 12.5510, Time = 7.24s\n",
            "Step = 2000, Avg Loss = 6.5929, Time = 2.60s\n",
            "Step = 3000, Avg Loss = 5.7223, Time = 2.81s\n",
            "Step = 4000, Avg Loss = 5.3758, Time = 2.60s\n",
            "Step = 5000, Avg Loss = 5.2020, Time = 2.62s\n",
            "Step = 6000, Avg Loss = 5.1222, Time = 2.69s\n",
            "Step = 7000, Avg Loss = 5.0808, Time = 2.61s\n",
            "Step = 8000, Avg Loss = 5.0608, Time = 2.66s\n",
            "Step = 9000, Avg Loss = 5.0364, Time = 2.83s\n",
            "Step = 10000, Avg Loss = 5.0290, Time = 2.66s\n",
            "Step = 11000, Avg Loss = 5.0161, Time = 2.73s\n",
            "Step = 12000, Avg Loss = 5.0041, Time = 2.69s\n",
            "Step = 13000, Avg Loss = 5.0055, Time = 2.61s\n",
            "Step = 14000, Avg Loss = 4.9936, Time = 2.64s\n",
            "Step = 15000, Avg Loss = 4.9864, Time = 2.59s\n",
            "Step = 16000, Avg Loss = 4.9814, Time = 2.62s\n",
            "Step = 17000, Avg Loss = 4.9828, Time = 2.64s\n",
            "Step = 18000, Avg Loss = 4.9771, Time = 2.72s\n",
            "Step = 19000, Avg Loss = 4.9748, Time = 2.87s\n",
            "Step = 20000, Avg Loss = 4.9656, Time = 3.03s\n",
            "Step = 21000, Avg Loss = 4.9710, Time = 2.72s\n",
            "Step = 22000, Avg Loss = 4.9653, Time = 2.69s\n",
            "Step = 23000, Avg Loss = 4.9630, Time = 2.62s\n",
            "Step = 24000, Avg Loss = 4.9656, Time = 2.66s\n",
            "Step = 25000, Avg Loss = 4.9570, Time = 2.85s\n",
            "Step = 26000, Avg Loss = 4.9594, Time = 2.63s\n",
            "Step = 27000, Avg Loss = 4.9564, Time = 2.62s\n",
            "Step = 28000, Avg Loss = 4.9542, Time = 2.67s\n",
            "Step = 29000, Avg Loss = 4.9592, Time = 2.66s\n",
            "Step = 30000, Avg Loss = 4.9573, Time = 2.66s\n",
            "Step = 31000, Avg Loss = 4.9535, Time = 2.77s\n",
            "Step = 32000, Avg Loss = 4.9493, Time = 2.61s\n",
            "Step = 33000, Avg Loss = 4.9489, Time = 2.66s\n",
            "Step = 34000, Avg Loss = 4.9511, Time = 2.76s\n",
            "Step = 35000, Avg Loss = 4.9517, Time = 2.62s\n",
            "Step = 36000, Avg Loss = 4.9514, Time = 2.63s\n",
            "Step = 37000, Avg Loss = 4.9459, Time = 2.74s\n",
            "Step = 38000, Avg Loss = 4.9429, Time = 2.60s\n",
            "Step = 39000, Avg Loss = 4.9407, Time = 2.64s\n",
            "Step = 40000, Avg Loss = 4.9441, Time = 2.65s\n",
            "Step = 41000, Avg Loss = 4.9456, Time = 2.61s\n",
            "Step = 42000, Avg Loss = 4.9449, Time = 2.74s\n",
            "Step = 43000, Avg Loss = 4.9427, Time = 2.62s\n",
            "Step = 44000, Avg Loss = 4.9405, Time = 2.57s\n",
            "Step = 45000, Avg Loss = 4.9445, Time = 2.61s\n",
            "Step = 46000, Avg Loss = 4.9464, Time = 2.61s\n",
            "Step = 47000, Avg Loss = 4.9408, Time = 2.57s\n",
            "Step = 48000, Avg Loss = 4.9425, Time = 2.77s\n",
            "Step = 49000, Avg Loss = 4.9424, Time = 2.59s\n",
            "Step = 50000, Avg Loss = 4.9447, Time = 2.62s\n",
            "Step = 51000, Avg Loss = 4.9435, Time = 2.66s\n",
            "Step = 52000, Avg Loss = 4.9430, Time = 2.63s\n",
            "Step = 53000, Avg Loss = 4.9432, Time = 2.68s\n",
            "Step = 54000, Avg Loss = 4.9434, Time = 2.78s\n",
            "Step = 55000, Avg Loss = 4.9430, Time = 2.66s\n",
            "Step = 56000, Avg Loss = 4.9386, Time = 2.88s\n",
            "Step = 57000, Avg Loss = 4.9384, Time = 2.62s\n",
            "Step = 58000, Avg Loss = 4.9420, Time = 2.58s\n",
            "Step = 59000, Avg Loss = 4.9429, Time = 2.59s\n",
            "Step = 60000, Avg Loss = 4.9425, Time = 2.59s\n",
            "Step = 61000, Avg Loss = 4.9419, Time = 2.61s\n",
            "Step = 62000, Avg Loss = 4.9442, Time = 2.63s\n",
            "Step = 63000, Avg Loss = 4.9407, Time = 2.66s\n",
            "Step = 64000, Avg Loss = 4.9395, Time = 2.59s\n",
            "Step = 65000, Avg Loss = 4.9423, Time = 2.77s\n",
            "Step = 66000, Avg Loss = 4.9445, Time = 2.60s\n",
            "Step = 67000, Avg Loss = 4.9429, Time = 2.59s\n",
            "Step = 68000, Avg Loss = 4.9459, Time = 2.57s\n",
            "Step = 69000, Avg Loss = 4.9411, Time = 2.59s\n",
            "Step = 70000, Avg Loss = 4.9459, Time = 2.67s\n",
            "Step = 71000, Avg Loss = 4.9436, Time = 2.67s\n",
            "Step = 72000, Avg Loss = 4.9454, Time = 2.58s\n",
            "Step = 73000, Avg Loss = 4.9423, Time = 2.67s\n",
            "Step = 74000, Avg Loss = 4.9417, Time = 2.78s\n",
            "Step = 75000, Avg Loss = 4.9401, Time = 2.61s\n",
            "Step = 76000, Avg Loss = 4.9423, Time = 2.71s\n",
            "Step = 77000, Avg Loss = 4.9431, Time = 2.63s\n",
            "Step = 78000, Avg Loss = 4.9450, Time = 2.58s\n",
            "Step = 79000, Avg Loss = 4.9418, Time = 2.76s\n",
            "Step = 80000, Avg Loss = 4.9446, Time = 2.60s\n",
            "Step = 81000, Avg Loss = 4.9430, Time = 2.59s\n",
            "Step = 82000, Avg Loss = 4.9442, Time = 2.61s\n",
            "Step = 83000, Avg Loss = 4.9412, Time = 2.62s\n",
            "Step = 84000, Avg Loss = 4.9454, Time = 2.64s\n",
            "Step = 85000, Avg Loss = 4.9435, Time = 2.67s\n",
            "Step = 86000, Avg Loss = 4.9449, Time = 2.64s\n",
            "Step = 87000, Avg Loss = 4.9487, Time = 2.63s\n",
            "Step = 88000, Avg Loss = 4.9390, Time = 2.73s\n",
            "Step = 89000, Avg Loss = 4.9467, Time = 2.59s\n",
            "Step = 90000, Avg Loss = 4.9467, Time = 2.56s\n",
            "Step = 91000, Avg Loss = 4.9404, Time = 2.58s\n",
            "Step = 92000, Avg Loss = 4.9439, Time = 2.59s\n",
            "Step = 93000, Avg Loss = 4.9360, Time = 2.88s\n",
            "Step = 94000, Avg Loss = 4.9383, Time = 2.61s\n",
            "Step = 95000, Avg Loss = 4.9449, Time = 2.61s\n",
            "Step = 96000, Avg Loss = 4.9463, Time = 2.66s\n",
            "Step = 97000, Avg Loss = 4.9421, Time = 2.62s\n",
            "Step = 98000, Avg Loss = 4.9445, Time = 2.63s\n",
            "Step = 99000, Avg Loss = 4.9433, Time = 2.74s\n",
            "Step = 100000, Avg Loss = 4.9403, Time = 2.60s\n",
            "Step = 101000, Avg Loss = 4.9404, Time = 2.60s\n",
            "Step = 102000, Avg Loss = 4.9441, Time = 2.72s\n",
            "Step = 103000, Avg Loss = 4.9458, Time = 2.58s\n",
            "Step = 104000, Avg Loss = 4.9424, Time = 2.60s\n",
            "Step = 105000, Avg Loss = 4.9467, Time = 2.56s\n",
            "Step = 106000, Avg Loss = 4.9428, Time = 2.57s\n",
            "Step = 107000, Avg Loss = 4.9445, Time = 2.63s\n",
            "Step = 108000, Avg Loss = 4.9453, Time = 2.63s\n",
            "Step = 109000, Avg Loss = 4.9470, Time = 2.60s\n",
            "Step = 110000, Avg Loss = 4.9419, Time = 2.70s\n",
            "Step = 111000, Avg Loss = 4.9430, Time = 2.83s\n",
            "Step = 112000, Avg Loss = 4.9365, Time = 2.59s\n",
            "Step = 113000, Avg Loss = 4.9404, Time = 2.60s\n",
            "Step = 114000, Avg Loss = 4.9438, Time = 2.64s\n",
            "Step = 115000, Avg Loss = 4.9441, Time = 2.68s\n",
            "Step = 116000, Avg Loss = 4.9411, Time = 2.80s\n",
            "Step = 117000, Avg Loss = 4.9473, Time = 2.55s\n",
            "Step = 118000, Avg Loss = 4.9394, Time = 2.60s\n",
            "Step = 119000, Avg Loss = 4.9414, Time = 2.66s\n",
            "Step = 120000, Avg Loss = 4.9430, Time = 2.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-43db8b306b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                              \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                              epochs=20)):\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     <1. convert data to tensors>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-3020837d494f>\u001b[0m in \u001b[0;36mmake_cbow_batchs_iter\u001b[0;34m(contexts, window_size, batch_size, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mcentral_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcentral_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFik_6djvg3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqDmuu7m_PB5",
        "colab_type": "text"
      },
      "source": [
        "# Дополнительные материалы\n",
        "## Почитать\n",
        "[On word embeddings - Part 1, Sebastian Ruder](http://ruder.io/word-embeddings-1/)  \n",
        "[On word embeddings - Part 2: Approximating the Softmax, Sebastian Ruder](http://ruder.io/word-embeddings-softmax/index.html)  \n",
        "[Word2Vec Tutorial - The Skip-Gram Model, ](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
        "\n",
        "## Посмотреть\n",
        "[cs224n \"Lecture 2 - Word Vector Representations: word2vec\"](https://www.youtube.com/watch?v=ERibwqs9p38&index=2&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)  \n",
        "[cs224n \"Lecture 5 - Backpropagation\"](https://www.youtube.com/watch?v=isPiE-DBagM&index=5&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9C1i3Y-6kv",
        "colab_type": "text"
      },
      "source": [
        "# Сдача задания\n",
        "\n",
        "[Сдача](https://goo.gl/forms/rzWjQQsGpqYNz5yt1)  \n",
        "[Опрос](https://goo.gl/forms/as640TWE058bFTpy2)"
      ]
    }
  ]
}